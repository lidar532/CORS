{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CORS_Lib.ipynb\n",
    "( CORS_Lib_asof: 2023-0606-1550 )\n",
    "Gather RINEX data sets from https://geodesy.noaa.gov/cors/rinex/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "(c) 2020, 2021. 2022, 2023 C. W. Wright  \n",
    "\n",
    "\n",
    "**Important Note:** High rate (1 Hz) is avaliable from CORS for only 30 days.  Data older than 30 days, at sampling intervals faster than every 30 seconds, can be had by contacting: https://www.avl.class.noaa.gov/saa/products/search?datatype_family=CORS\n",
    "\n",
    "** Visit https://geodesy.noaa.gov/CORS/data.shtml for details on sp3 for gps & glonas, and also nav files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Todo list\n",
    "* Add code to trim to desired time range.\n",
    "* Add code to create a panel widget\n",
    "* Add code to gather and merge \"same day\" data. [(see teqc merge post here)](https://postal.unavco.org/pipermail/teqc/2014/001827.html)\n",
    "* Switch to [Juypter Widgets](https://ipywidgets.readthedocs.io/en/latest/index.html)\n",
    "* Add [multiprocessing](https://pymotw.com/2/multiprocessing/basics.html) to gather all the stations in parallel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Change Log & Bug Fixes\n",
    "* 2023-0608\n",
    "  * Split up to create a Python package\n",
    "* 2023-0601\n",
    "  * Modified install_teqc() to download all versions, and test each one to\n",
    "    make sure it works.\n",
    "* 2023-0531\n",
    "  * Added code to add CORS plots to collection.\n",
    "* 2023-0530\n",
    "  * Added mew code to fix the issue with downloading sp3 files.\n",
    "  * Reorganized directory structure to be abit more like the CORS site.\n",
    "  * Significant changes to do more from wget.\n",
    "  * Added code to add the CORS readme.txt and rinex211.txt document.\n",
    "\n",
    "* 2020-1019\n",
    "  * Added tool cells for gzip, gunzip, mv, RINEX time span extract\n",
    "  * Added number of lines selector to the display file cell\n",
    "  * Consoldated all the defs into one cell to make it easier to use stand-alone\n",
    "  * Added tool to show the size of a Path_Name\n",
    "\n",
    "* 2020-1018\n",
    "  * Fixed problem where teqc wasn't loading and thus not allowing a RINEX file to be cut by time\n",
    "* 2020-0622\n",
    "  * Added input validity checking to time input strings.\n",
    "  * Initial commit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Library Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#title imports & Installs: Fetch CORS GNSS data for 1 or more sites on a date. { form-width: \"35%\", display-mode: \"form\" }\n",
    "import datetime\n",
    "import time\n",
    "import os\n",
    "import glob\n",
    "import inspect\n",
    "import ipywidgets       as ipw\n",
    "import multiprocessing\n",
    "import numpy            as np\n",
    "import pandas           as pd\n",
    "import panel            as pn\n",
    "import re\n",
    "import requests\n",
    "import subprocess       as sp\n",
    "\n",
    "from   bs4              import BeautifulSoup\n",
    "from   pathlib          import Path\n",
    "\n",
    "try:\n",
    "  import google.colab\n",
    "  IN_COLAB = True\n",
    "except:\n",
    "  IN_COLAB = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Globals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     IN_COLAB: False\n",
      "    local_bin: /home/wright/bin/\n",
      "CORS_Lib_asof: CORS_Lib_asof: 2023-0606-1550\n",
      "     base_url: https://geodesy.noaa.gov/\n",
      "    rinex_url: https://geodesy.noaa.gov/corsdata/rinex/\n"
     ]
    }
   ],
   "source": [
    "CORS_Lib_asof = 'CORS_Lib_asof: 2023-0606-1550'\n",
    "\n",
    "base_url           = 'https://geodesy.noaa.gov/'\n",
    "rinex_url          = base_url+'corsdata/rinex/'\n",
    "coords_url         = base_url+'corsdata/coord/coord_14/'\n",
    "plots_url          = base_url+'corsdata/Plots/'\n",
    "station_log_url    = base_url+'corsdata/station_log/'\n",
    "cors_info_url_list = [ base_url+'/corsdata/readme.txt', \n",
    "                      base_url+'/corsdata/RINEX211.txt' ]\n",
    "\n",
    "teqc_list          = [ \n",
    "    'https://www.unavco.org/software/data-processing/teqc/development/teqc_CentOSLx86_64s.zip',\n",
    "    'https://www.unavco.org/software/data-processing/teqc/development/teqc_CentOSLx86_64d.zip',\n",
    "    'https://www.unavco.org/software/data-processing/teqc/development/teqc_Lx86_64d.zip',\n",
    "    'https://www.unavco.org/software/data-processing/teqc/development/teqc_Lx86_64s.zip'\n",
    "]\n",
    "\n",
    "test_folder = '/tmp/test/'\n",
    "\n",
    "if IN_COLAB:\n",
    "  local_bin = '/usr/local/bin'\n",
    "else:\n",
    "  local_bin = f'{str(Path.home())}/bin/'\n",
    "\n",
    "if __name__ == '__main__':\n",
    "  print(f'     IN_COLAB: {IN_COLAB}')\n",
    "  print(f'    local_bin: {local_bin}')\n",
    "  print(f'CORS_Lib_asof: {CORS_Lib_asof}')\n",
    "  print(f'     base_url: {base_url}')\n",
    "  print(f'    rinex_url: {rinex_url}')\n",
    "\n",
    "wget_return_codes = ('0, No problems occurred.', \n",
    "                     '1, Generic error code.',\n",
    "                     '2, Parse error---for instance, when parsing command-line options, the .wgetrc or .netrc...',\n",
    "                     '3, File I/O error.',\n",
    "                     '4, Network failure.',\n",
    "                     '5, SSL verification failure.',\n",
    "                     '6, Username/password authentication failure.',\n",
    "                     '7, Protocol errors.',\n",
    "                     '8, Server issued an error response.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### def install_teqc():\n",
    "See: https://www.unavco.org/software/data-processing/teqc/teqc.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#title def install_teqc()  { form-width: \"35%\", display-mode: \"form\" }\n",
    "# Get and install teqc\n",
    "def install_teqc():\n",
    "  '''\n",
    "  This function is used to install the teqc software from Unavco. It first\n",
    "  checks if the teqc software is already installed in the system. If not, \n",
    "  it downloads the teqc_Lx86_64s.zip file from Unavco, unzips it, creates\n",
    "  a local bin directory and moves the teqc file to the local bin directory.\n",
    "  Finally, it deletes the zip file.\n",
    "\n",
    "  See: https://www.unavco.org/software/data-processing/teqc/teqc.html\n",
    "\n",
    "  Parameters:\n",
    "  None\n",
    "\n",
    "  Returns:\n",
    "  A string indicating the state of the installation. \n",
    "  It can be either: 'Teqc installed.', 'Teqc was already installed.', or 'teqc install failed.'\n",
    "  '''\n",
    "  state = 'initial.'\n",
    "  os.chdir('/tmp/')\n",
    "  print(f'install_teqc(): ')\n",
    "  rv = os.path.isfile(f'{local_bin}teqc')\n",
    "  if rv == False:\n",
    "    state = 'teqc install failed.'\n",
    "    for teqc_zip in teqc_list:\n",
    "        print(f'Downloading {teqc_zip} and installing Teqc from Unavco.  ')\n",
    "        sp.run(f'wget {teqc_zip}',                  shell=True)\n",
    "        teqc_zip_fn = teqc_zip.split( '/')[-1]\n",
    "        rv = sp.run(f'unzip -o {teqc_zip_fn}',       shell=True)\n",
    "        sp.run(f'rm -rf {teqc_zip_fn}',              shell=True)\n",
    "        rv = sp.run(f'/tmp/teqc -help',              shell=True, capture_output=True )\n",
    "        if rv.returncode == 0 :\n",
    "            print('Installing teqc.')\n",
    "            sp.run(f'mkdir -p {local_bin}',          shell=True)\n",
    "            sp.run(f'mv -f teqc {local_bin}',        shell=True)  \n",
    "            state = ' Teqc installed.'\n",
    "            break\n",
    "        else:\n",
    "            print(f'Install failed.  rv.return={rv.returncode}')\n",
    "            print(rv)\n",
    "  else:\n",
    "    a = 1;\n",
    "    state='Teqc was already installed.'\n",
    "  return state\n",
    "\n",
    "# Local test and debug code.\n",
    "if False:\n",
    "  test_teqc_state = install_teqc()\n",
    "  print(test_teqc_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### def extract_year( date ):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#=================================================================================\n",
    "#title def extract_year( date ) { form-width: \"35%\", display-mode: \"form\" }\n",
    "def extract_year( date ):\n",
    "  Year = date.split('/')[0]\n",
    "  return Year"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### def isTimeFormat(ts):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#title def isTimeFormat(ts)  { form-width: \"35%\", display-mode: \"form\" }\n",
    "def isTimeFormat(ts):\n",
    "  \"\"\"\n",
    "  isTimeFormat(ts) checks the 'ts' input string for validity. A valid string is in\n",
    "  this format: '13:34:56'.\n",
    "\n",
    "  Returns True for a valid string,a nd False for invalid.\n",
    "  \n",
    "  \"\"\"\n",
    "  t = []\n",
    "  rv = False;\n",
    "  try:\n",
    "      t = time.strptime(ts, '%H:%M:%S')\n",
    "      rv = True;\n",
    "  except ValueError:\n",
    "      rv = False\n",
    "  return rv\n",
    "\n",
    "# testing code...\n",
    "if False:\n",
    "  for t in ['12:34:56',\n",
    "            '12:34',\n",
    "            '01:02:03',\n",
    "            '23:01:02',\n",
    "            '25:34:63']:\n",
    "    print(f'rv:{isTimeFormat(t)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### def utctoweekseconds(utc,leapseconds):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def utctoweekseconds(utc,leapseconds):\n",
    "  '''\n",
    "    This function takes two parameters, utc and leapseconds, and returns the\n",
    "    GPS week, the GPS day, and the seconds and microseconds since the beginning of the GPS week.\n",
    "\n",
    "    Parameters:\n",
    "    utc (datetime.datetime): The UTC time to be converted.\n",
    "    leapseconds (int): The number of leap seconds to be added to the UTC time.\n",
    "\n",
    "    Returns:\n",
    "    A tuple containing the GPS week, the GPS day, and the seconds and \n",
    "    microseconds since the beginning of the GPS week.\n",
    "\n",
    "    The GPS week is an integer representing the number of weeks since the \n",
    "    beginning of the GPS epoch (1980-01-06 00:00:00).\n",
    "    The GPS day is an integer representing the number of days since the \n",
    "    beginning of the GPS week.\n",
    "    The seconds and microseconds since the beginning of the GPS week are both\n",
    "    integers representing the number of seconds and microseconds since the\n",
    "    beginning of the GPS week.\n",
    "\n",
    "    Example:\n",
    "    utc = datetime.datetime(2020, 1, 1, 0, 0, 0)\n",
    "    leapseconds = 18\n",
    "\n",
    "    utctoweekseconds(utc, leapseconds)\n",
    "\n",
    "    Returns: (2086, 0, 0, 0)\n",
    "  '''\n",
    "  import datetime, calendar\n",
    "  datetimeformat = \"%Y-%m-%d %H:%M:%S\"\n",
    "  epoch = datetime.datetime.strptime(\"1980-01-06 00:00:00\",datetimeformat)\n",
    "  tdiff = utc -epoch  + datetime.timedelta(seconds=leapseconds)\n",
    "  gpsweek = tdiff.days // 7 \n",
    "  gpsdays = tdiff.days - 7*gpsweek         \n",
    "  gpsseconds = tdiff.seconds + 86400* (tdiff.days -7*gpsweek) \n",
    "  return gpsweek,gpsdays,gpsseconds,tdiff.microseconds\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### def compute_day_of_year(date_str):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#title def compute_day_of_year(date_str) { form-width: \"35%\", display-mode: \"form\" }\n",
    "def compute_day_of_year(date_str):\n",
    "  '''\n",
    "    This function computes the day of the year from a given date string in the format 'YYYY/MM/DD'.\n",
    "\n",
    "    Parameters:\n",
    "    date_str (str): A string representing a date in the format 'YYYY/MM/DD'.\n",
    "\n",
    "    Returns:\n",
    "    A tuple containing the day of the year in the format 'YYYY/DDD', \n",
    "    the year as a string, the day as a string, the month as a string, \n",
    "    and the day as a string.\n",
    "\n",
    "    Example:\n",
    "    compute_day_of_year('2020/04/15')\n",
    "\n",
    "    Returns:\n",
    "    ('2020/105', '2020-0415-J105', '2020', '105', '04', '15')\n",
    "\n",
    "    The returned tuple contains the day of the year in the format 'YYYY/DDD', \n",
    "    the year as a string, the day as a string, the month as a string, \n",
    "    and the day as a string. The first element of the tuple is the day \n",
    "    of the year in the format 'YYYY/DDD', which is the year followed by the \n",
    "    day of the year. The second element of the tuple is the year as a string. \n",
    "    The third element of the tuple is the day as a string. The fourth element\n",
    "    of the tuple is the month as a string. The fifth element of the tuple is\n",
    "    the day as a string.\n",
    "\n",
    "  '''\n",
    "  JDay = int(( datetime.datetime.strptime(date_str,'%Y/%m/%d') - datetime.datetime(int(date_str.split('/')[0]),1,1)).days + 1 )\n",
    "  JDay = f'{JDay:03d}'\n",
    "  date_parts =  date_str.split('/')\n",
    "  Year = date_parts[0]\n",
    "  Month = f'{int(date_parts[1]):02d}'\n",
    "  Day   = f'{int(date_parts[2]):02d}'\n",
    "  return f'{Year}/{JDay}', f'{Year}-{Month}{Day}-J{JDay}', Year, JDay, Month, Day\n",
    "  \n",
    "if False:\n",
    "  test_dates = [\n",
    "      '2023/1/1',\n",
    "      '2023/01/01',\n",
    "      '2023/12/31',\n",
    "      '2023/05/20'\n",
    "  ]\n",
    "  print('All returned data:')\n",
    "  for d in test_dates:\n",
    "    print( f'{d:12} : { compute_day_of_year(d) } ')\n",
    "\n",
    "  print('\\nCORES path segment only:')\n",
    "  for d in test_dates:\n",
    "    print( f'{d:12} : { compute_day_of_year(d)[0]}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### def getHTMLdocument(url):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to extract html document from given url\n",
    "def getHTMLdocument(url):\n",
    "    response = requests.get(url)  # response will be provided in JSON format\n",
    "    return response.text\n",
    "\n",
    "if False:\n",
    "  print('Testing: getHTMLdocument(url):')\n",
    "  test_html = getHTMLdocument(rinex_url)\n",
    "  print(test_html)\n",
    "  print('Done.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### def download_urls(url_list, root_dir):\n",
    "Notes:\n",
    "1. It is important for a url to end in `/` \n",
    "when using recursive `-r` and `-np` options to `wget`. See: https://stackoverflow.com/questions/19004809/using-wget-to-recursively-fetch-a-directory-with-no-parent for details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_urls(url_list, folder, clobber=False, id='', options='', cut_dirs=4):\n",
    "  '''\n",
    "download_urls() is a function that downloads a list of URLs to a specified root directory.\n",
    "\n",
    "Parameters:\n",
    "url_list (list): A list of URLs to be downloaded.\n",
    "root_dir (str): The root directory to which the URLs will be downloaded.\n",
    "clobber (bool): A boolean value indicating whether existing files should be overwritten.\n",
    "id (str): An optional identifier for the download.\n",
    "options (str): An optional string of additional wget options.\n",
    "    \n",
    "    The function uses the wget command to download the URLs. The wget options used are:\n",
    "    -nv: Not verbose\n",
    "    -nc: No clobber (use for OSB files to avoid overwriting 1-Sec with 30-Sec)\n",
    "    -np: No parent. (Important)\n",
    "    -nH: Do not create a directory named after the url\n",
    "    --cut-dirs=4: Remove the first four subdirs\n",
    "    -R \"index.html*\": Do not keep the index.html* files.\n",
    "    -P xxx: xxx will be the root directory\n",
    "\n",
    "    Wget return codes:\n",
    "      0   No problems occurred.\n",
    "      1   Generic error code.\n",
    "      2   Parse error---for instance, when parsing command-line options, the .wgetrc or .netrc...\n",
    "      3   File I/O error.\n",
    "      4   Network failure.\n",
    "      5   SSL verification failure.\n",
    "      6   Username/password authentication failure.\n",
    "      7   Protocol errors.\n",
    "      8   Server issued an error response.\n",
    "  '''\n",
    "  # Wget Options:\n",
    "  # -nv                Not verbose\n",
    "  # -nc                No clobber (use for OSB files to avoid \n",
    "  #                    overwriting 1-Sec with 30-Sec)\n",
    "  # -np                No parent. ( Important !!! )\n",
    "  # -nH                Do not create a directory named after the url\n",
    "  # --cut-dirs=4       Remove the first four subdirs\n",
    "  # -R \"index.html*\"   Do not keep the index.html* files.\n",
    "  # -P xxx             xxx will be the root directory\n",
    "  os.makedirs(folder, exist_ok=True)\n",
    "  log_fn = datetime.datetime.now().strftime(f\"{folder}/%Y-%m%d-%H%M%S-CORS-wget-{id}-log.txt\")\n",
    "  url_str = ' '.join(url_list)\n",
    "\n",
    "  if clobber:\n",
    "    nc_switch = ''\n",
    "  else:\n",
    "    nc_switch = '-nc '\n",
    "\n",
    "  rv = sp.run( \n",
    "      'wget '\\\n",
    "      f'{nc_switch} '\\\n",
    "      f'-o {log_fn} '\\\n",
    "      '-nv '\\\n",
    "      f'-P {folder} '\\\n",
    "      '-np '\\\n",
    "      '-r '\\\n",
    "      '-nH '\\\n",
    "      '--connect-timeout=10 '\\\n",
    "      '--read-timeout=10 '\\\n",
    "      f'--cut-dirs={cut_dirs} '\\\n",
    "      '-R \"index.html*,robots.txt,*.tmp\" '\\\n",
    "      f'{url_str}',\n",
    "        shell=True, capture_output=True)\n",
    "  rv.stderr = log_fn\n",
    "  rv.id = id\n",
    "  return rv\n",
    "\n",
    "if False:\n",
    "  # Test with some sp3 and nav data.\n",
    "  test_url      = rinex_url\n",
    "  fn = f'{test_folder}/sp3_nav'\n",
    "  test_url_list = CORS_get_Support_url_list(test_url, date='2023/04/28')\n",
    "  rv = download_urls(test_url_list, folder=fn, id='sp3')\n",
    "  rv_str = wget_return_codes[rv.returncode]\n",
    "  print(f'Operation completed. The Wget response was: {rv_str}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### def CORS_trim_to_time(f, start, stop):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Url for data: https://geodesy.noaa.gov/cors/coord/coord_14/\n",
    "def CORS_trim_to_time(f, start, stop):\n",
    "  \"\"\"\n",
    "Trims a RINEX file (f) to be between the 'start' and 'stop' times given.\n",
    "\n",
    "This function takes in a file name (f), start time (start) and \n",
    "stop time (stop) as parameters and trims the file to the given time range.\n",
    "\n",
    "The start and stop times are first converted to a format without colons, \n",
    "hyphens and periods. The teqc command is then used to trim the file to \n",
    "the given time range and the output is stored in a temporary file. \n",
    "The temporary file is then moved to the original file name.\n",
    "\n",
    "Parameters:\n",
    "f (str): The file name to be trimmed.\n",
    "start (str): The start time in the format 'YYYY-MM-DD HH:MM:SS.SSS'.\n",
    "stop (str): The stop time in the format 'YYYY-MM-DD HH:MM:SS.SSS'.\n",
    "\n",
    "Returns:\n",
    "rv (CompletedProcess): A CompletedProcess object containing information about the run command.\n",
    "  \"\"\"\n",
    "  st = re.sub('[\\:\\-\\.]', '', start)\n",
    "  end = re.sub('[\\:\\-\\.]', '', stop)\n",
    "  print(f'CORS_trim_to_time(): f: {f}   start: {start}  stop: {stop}')\n",
    "  rv = sp.run(f'teqc +out tmp.txt -st {start} -e {stop} {f}', shell=True)\n",
    "  sp.run(f'mv tmp.txt {f}', shell=True)\n",
    "  return rv\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### def CORS_get_station_log_url(station_list):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CORS_get_station_log_url(station_list):\n",
    "  '''\n",
    "    This function takes a list of station names as an argument and \n",
    "    returns a list of URLs for the station log files.\n",
    "\n",
    "    Parameters:\n",
    "    station_list (list): A list of station names.\n",
    "\n",
    "    Returns:\n",
    "    lst (list): A list of URLs for the station log files.\n",
    "  '''\n",
    "  lst = []\n",
    "  for station in station_list:\n",
    "    station = str.lower(station)\n",
    "    cords_file = f'{station_log_url}{station}.log.txt'\n",
    "    lst.append(cords_file)\n",
    "  return lst\n",
    "\n",
    "if False:\n",
    "  station_list  = ['ncdu', 'ncbe', 'NCRT', 'loy2']\n",
    "  local_test_folder = test_folder\n",
    "  rv = CORS_get_station_log_url( station_list )\n",
    "  display(rv)\n",
    "  print('Done.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### def down_load_cors_station_log( dir, station_list):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def down_load_cors_station_log( dir, station_list):\n",
    "  '''\n",
    "    This function downloads the log files of the given CORS stations \n",
    "    from the NGS website.\n",
    "\n",
    "    Parameters:\n",
    "    dir (str): The directory where the log files should be downloaded.\n",
    "    station_list (list): A list of CORS station names.\n",
    "\n",
    "    Returns:\n",
    "    rv (dict): A dictionary containing the station name as the key and \n",
    "    the path of the downloaded log file as the value.\n",
    "  '''\n",
    "  log_file_list = CORS_get_station_log_url(station_list)\n",
    "  rv = download_urls(log_file_list, dir, id='station', cut_dirs=1)\n",
    "  return rv\n",
    "\n",
    "if False:\n",
    "  station_list  = ['ncdu', 'ncbe', 'NCRT', 'loy2']\n",
    "  local_test_folder = test_folder\n",
    "  rv = down_load_cors_station_log( local_test_folder, station_list )\n",
    "  print(f'{wget_return_codes[rv.returncode]} See: {rv.stderr}' )\n",
    "  print('Done.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### def CORS_get_station_plots_url(station_list):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CORS_get_station_plots_url(station_list):\n",
    "  '''\n",
    "    This function takes a list of station names as an argument and \n",
    "    returns a list of URLs for the corresponding station plot \n",
    "    files.\n",
    "\n",
    "    Parameters:\n",
    "    station_list (list): A list of station names.\n",
    "\n",
    "    Returns:\n",
    "    lst (list): A list of URLs for the corresponding station plot\n",
    "     files.\n",
    "  '''\n",
    "  # Example: https://geodesy.noaa.gov/corsdata/Plots/ab02_14.short.png\n",
    "  lst = []\n",
    "  for station in station_list:\n",
    "    station = str.lower(station)\n",
    "    short_plots_file = f'{plots_url}{station}_14.short.png'\n",
    "    long_plots_file  = f'{plots_url}Longterm/{station}_14.long.png'\n",
    "    lst.append(short_plots_file)\n",
    "    lst.append(long_plots_file)\n",
    "  return lst\n",
    "\n",
    "if False:\n",
    "  print('Testing: CORS_get_station_plots_url()')\n",
    "  station_list  = ['ncdu', 'ncbe', 'NCRT', 'loy2']\n",
    "  rv = CORS_get_station_plots_url( station_list )\n",
    "  display(rv)\n",
    "  print('Done.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### def down_load_cors_plots( dir, station_list):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def down_load_cors_plots( dir, station_list):\n",
    "  '''\n",
    "    This function downloads the plots of the CORS stations from\n",
    "     the NGS website.\n",
    "\n",
    "    Parameters:\n",
    "        dir (str): The directory where the files will be downloaded.\n",
    "        station_list (list): A list of CORS station names.\n",
    "\n",
    "    Returns:\n",
    "        rv (list): A list of the downloaded files.\n",
    "  '''\n",
    "  plots_file_list = CORS_get_station_plots_url(station_list)\n",
    "  rv = download_urls(plots_file_list, dir, id='Plots', cut_dirs=1)\n",
    "  return rv\n",
    "\n",
    "if False:\n",
    "  print('Testing: down_load_cors_plots_coords()')\n",
    "  station_list  = ['ncdu', 'ncbe', 'NCRT', 'loy2']\n",
    "  local_test_folder = test_folder\n",
    "  rv = down_load_cors_plots( local_test_folder, station_list )\n",
    "  display(rv)\n",
    "  print(f'{wget_return_codes[rv.returncode]} See: {rv.stderr}' )\n",
    "  print('Done.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### def CORS_get_station_coords_url(dir, station_list):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CORS_get_station_coords_url(station_list):\n",
    "  '''\n",
    "    This function takes a list of station names as an argument and \n",
    "    returns a list of URLs for the corresponding station coordinates \n",
    "    files.\n",
    "\n",
    "    Parameters:\n",
    "    station_list (list): A list of station names.\n",
    "\n",
    "    Returns:\n",
    "    lst (list): A list of URLs for the corresponding station coordinates\n",
    "     files.\n",
    "  '''\n",
    "  lst = []\n",
    "  for station in station_list:\n",
    "    station = str.lower(station)\n",
    "    cords_file = f'{coords_url}{station}_14.coord.txt'\n",
    "    lst.append(cords_file)\n",
    "  return lst\n",
    "\n",
    "if False:\n",
    "  print('Testing: CORS_get_station_coords_url()')\n",
    "  station_list  = ['ncdu', 'ncbe', 'NCRT', 'loy2']\n",
    "  rv = CORS_get_station_coords_url( station_list )\n",
    "  display(rv)\n",
    "  print('Done.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### def down_load_cors_station_coords( dir, station_list):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def down_load_cors_station_coords( dir, station_list):\n",
    "  '''\n",
    "    This function downloads the coordinates of the CORS stations from the NGS website.\n",
    "\n",
    "    Parameters:\n",
    "        dir (str): The directory where the files will be downloaded.\n",
    "        station_list (list): A list of CORS station names.\n",
    "\n",
    "    Returns:\n",
    "        rv (list): A list of the downloaded files.\n",
    "  '''\n",
    "  coords_file_list = CORS_get_station_coords_url(station_list)\n",
    "  rv = download_urls(coords_file_list, dir, id='coords', cut_dirs=2)\n",
    "  return rv\n",
    "\n",
    "if False:\n",
    "  print('Testing: down_load_cors_station_coords()')\n",
    "  station_list  = ['ncdu', 'ncbe', 'NCRT', 'loy2']\n",
    "  local_test_folder = test_folder\n",
    "  rv = down_load_cors_station_coords( local_test_folder, station_list )\n",
    "  display(rv)\n",
    "  print(f'{wget_return_codes[rv.returncode]} See: {rv.stderr}' )\n",
    "  print('Done.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### def clean_up_CORS(rdir, date):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_up_CORS(rdir, date):\n",
    "  \"\"\"\n",
    "  clean_up_CORS(rdir, date)\n",
    "  Inputs:\n",
    "  rdir      Directory to start the find command in.\n",
    "  date      The date of the CORS files to cleanup.\n",
    "\n",
    "  Outputs:\n",
    "            Removes unnecessary files.\n",
    "  Returns:\n",
    "            None.\n",
    "\n",
    "  Uses the Linux 'find' command to locate and remove unnecessary files \n",
    "  from within a CORS station directory.  \n",
    "  \"\"\"\n",
    "  Year = date.split('/')[0][2:4]\n",
    "  rv = sp.check_output(f'cd {rdir}; find -name *.md5 -delete; find -name *.{Year}d -delete; find -name *.md5* -delete; find -name *.{Year}S* -delete;', shell=True) \n",
    "  return rv\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### def CORS_get_Support_url_list( base_url, date, file_types=\"sp3.gz|n.gz|g.gz\" ):\n",
    "See: https://www.geeksforgeeks.org/beautifulsoup-scraping-link-from-html/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CORS_get_Support_url_list( base_url, date, file_types=\"sp3.gz|n.gz|g.gz\" ):\n",
    "  data_url = base_url+compute_day_of_year( date )[0]\n",
    "  hdoc = getHTMLdocument(data_url)\n",
    "  soup = BeautifulSoup( hdoc, 'html.parser')\n",
    "  urls = []\n",
    "  for link in soup.find_all('a', attrs={'href' : re.compile(file_types, re.IGNORECASE) } ):\n",
    "    #print(link.prettify())\n",
    "    fn = link.get('href')\n",
    "    url = f'{data_url}/{fn}'\n",
    "    urls.append(url)\n",
    "  return urls\n",
    "\n",
    "# Testing.\n",
    "if False:\n",
    "  print('Testing: CORS_get_Support_url_list()')\n",
    "  print('sp3.gz and n.gz and g.gz')\n",
    "  #url = 'https://geodesy.noaa.gov/corsdata/rinex/'\n",
    "  url = rinex_url\n",
    "  sp3_and_nav_urls = CORS_get_Support_url_list(url, date='2023/05/23')\n",
    "  for fn in sp3_and_nav_urls:\n",
    "    print(fn)\n",
    "\n",
    "  print('\\nsp3 only.')\n",
    "  file_types=\"sp3.gz\"\n",
    "  sp3_urls = CORS_get_Support_url_list(url, date='2023/05/23', file_types=\"sp3.gz\")\n",
    "  for fn in sp3_urls:\n",
    "    print(fn)\n",
    "\n",
    "  print('\\nn.gz and g.gz only.')\n",
    "  file_types=\"sp3.gz\"\n",
    "  nav_urls = CORS_get_Support_url_list(url, date='2023/05/23', file_types=\"n.gz|g.gz\")\n",
    "  for fn in nav_urls:\n",
    "    print(fn)\n",
    "  print('Done.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### def down_load_list_of_obs_files( folder='./', date='' station_list=[] ): "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def down_load_list_of_obs_files( folder='./', date='', station_list=[] ): \n",
    "  '''\n",
    "    down_load_list_of_obs_files(folder, date, station_list)\n",
    "\n",
    "    This function downloads a list of observation files from a given URL for a given date and station list.\n",
    "\n",
    "    Parameters:\n",
    "    folder (str): The folder where the files should be downloaded.\n",
    "    date (str): The date for which the files should be downloaded.\n",
    "    station_list (list): A list of stations for which the files should be downloaded.\n",
    "\n",
    "    Returns:\n",
    "    rv (list): A list of the downloaded files.\n",
    "  '''\n",
    "  # Create a string from the station list.\n",
    "  station_url_list = []\n",
    "  for station in station_list:\n",
    "    data_url = '/'.join([ rinex_url+compute_day_of_year( date )[0], station.lower()+'/'] )\n",
    "    station_url_list.append(data_url)\n",
    "  \n",
    "  # download the files.\n",
    "  rv = download_urls(station_url_list, folder=folder,  id='OBS')\n",
    "  return rv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### def down_load_cors_data( folder = '/', date   = '', station_list = [] ):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def down_load_cors_data( folder = '/tmp', date = '', station_list = [] ):\n",
    "  \n",
    "  def show_progress(msg):\n",
    "    print(msg)\n",
    "\n",
    "  show_progress('')\n",
    "  target_folder = f'{folder}/{compute_day_of_year(date)[1]}-CORS'\n",
    "  show_progress(f'saving to: {target_folder}')\n",
    "  rv_lst = []\n",
    "\n",
    "  show_progress('Downloading info on selected stations.')\n",
    "  rv = download_urls(cors_info_url_list, target_folder, id='info')\n",
    "  rv_lst.append(rv)\n",
    "\n",
    "  show_progress('Downloading selected OBS files.')\n",
    "  rv = down_load_list_of_obs_files( \n",
    "    folder=target_folder, \n",
    "    date=date, \n",
    "    station_list=station_list\n",
    "  )\n",
    "  rv_lst.append(rv)\n",
    "\n",
    "  show_progress('Downloading sp3 & nav files.')\n",
    "  url_list = CORS_get_Support_url_list( rinex_url, date = date )\n",
    "  sp3_nav_folder = '/'.join([target_folder, 'sp3_nav'])\n",
    "  rv = download_urls(url_list, folder = sp3_nav_folder, id='sp3')\n",
    "  rv_lst.append(rv)\n",
    "\n",
    "  show_progress('Downloading station coords, logs, and plots.')\n",
    "  for func in [down_load_cors_station_coords, \n",
    "               down_load_cors_station_log,\n",
    "               down_load_cors_plots ]:\n",
    "    rv = func(target_folder, station_list)\n",
    "    rv_lst.append(rv)\n",
    "\n",
    "  show_progress('All downloads completed.')\n",
    "  return rv_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
