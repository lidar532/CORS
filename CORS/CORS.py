# AUTOGENERATED! DO NOT EDIT! File to edit: ../nbs/00_CORS.ipynb.

# %% auto 0
__all__ = ['CORS_Lib_asof', 'base_url', 'rinex_url', 'coords_url', 'plots_url', 'station_log_url', 'cors_info_url_list',
           'test_folder', 'wget_return_codes', 'teqc_list', 'install_teqc', 'extract_year', 'isTimeFormat',
           'utctoweekseconds', 'compute_day_of_year', 'getHTMLdocument', 'CORS_get_Support_url_list', 'download_urls',
           'CORS_trim_to_time', 'CORS_get_station_log_url', 'down_load_cors_station_log', 'CORS_get_station_plots_url',
           'down_load_cors_plots', 'CORS_get_station_coords_url', 'down_load_cors_station_coords', 'clean_up_CORS',
           'down_load_list_of_obs_files', 'down_load_cors_data']

# %% ../nbs/00_CORS.ipynb 8
import datetime
import time
import os
import glob
import inspect
import ipywidgets       as ipw
import multiprocessing
import numpy            as np
import pandas           as pd
import panel            as pn
import re
import requests
import subprocess       as sp

# %% ../nbs/00_CORS.ipynb 10
from   bs4              import BeautifulSoup
from   pathlib          import Path

# %% ../nbs/00_CORS.ipynb 12
try:
  import google.colab
  IN_COLAB = True
except:
  IN_COLAB = False

# %% ../nbs/00_CORS.ipynb 15
CORS_Lib_asof      = 'CORS_Lib_asof: 2023-0614-1908'

# %% ../nbs/00_CORS.ipynb 17
base_url           = 'https://geodesy.noaa.gov/'
rinex_url          = base_url+'corsdata/rinex/'
coords_url         = base_url+'corsdata/coord/coord_14/'
plots_url          = base_url+'corsdata/Plots/'
station_log_url    = base_url+'corsdata/station_log/'
cors_info_url_list = [ base_url+'/corsdata/readme.txt', 
                      base_url+'/corsdata/RINEX211.txt' ]

# %% ../nbs/00_CORS.ipynb 19
test_folder = '/tmp/test/'

# %% ../nbs/00_CORS.ipynb 21
wget_return_codes = ('0, No problems occurred.', 
                     '1, Generic error code.',
                     '2, Parse error---for instance, when parsing command-line options, the .wgetrc or .netrc...',
                     '3, File I/O error.',
                     '4, Network failure.',
                     '5, SSL verification failure.',
                     '6, Username/password authentication failure.',
                     '7, Protocol errors.',
                     '8, Server issued an error response.')

# %% ../nbs/00_CORS.ipynb 23
teqc_list          = [ 
    'https://www.unavco.org/software/data-processing/teqc/development/teqc_CentOSLx86_64s.zip',
    'https://www.unavco.org/software/data-processing/teqc/development/teqc_CentOSLx86_64d.zip',
    'https://www.unavco.org/software/data-processing/teqc/development/teqc_Lx86_64d.zip',
    'https://www.unavco.org/software/data-processing/teqc/development/teqc_Lx86_64s.zip'
]

# %% ../nbs/00_CORS.ipynb 25
if IN_COLAB:
  local_bin = '/usr/local/bin'
else:
  local_bin = f'{str(Path.home())}/bin/'

# %% ../nbs/00_CORS.ipynb 29
# Get and install teqc
def install_teqc() ->str:
  '''
  This function is used to download and install the teqc software from 
  Unavco. It first checks if the teqc software is already installed
  in the system. If not, it downloads the teqc_Lx86_64s.zip file from
  Unavco, unzips it, creates a local bin directory and moves the teqc
  file to the local bin directory. Finally, it deletes the zip file.

  See: https://www.unavco.org/software/data-processing/teqc/teqc.html
  

  Parameters:
  None

  Returns:
  A string indicating the state of the installation. 
  It can be either: 'Teqc installed.', 'Teqc was already installed.', or
  'teqc install failed.'
  '''
  state = 'initial.'
  os.chdir('/tmp/')
  print(f'install_teqc(): ')
  rv = os.path.isfile(f'{local_bin}teqc')
  if rv == False:
    state = 'teqc install failed.'
    for teqc_zip in teqc_list:
        print(f'Downloading {teqc_zip} and installing Teqc from Unavco.  ')
        sp.run(f'wget {teqc_zip}',                  shell=True)
        teqc_zip_fn = teqc_zip.split( '/')[-1]
        rv = sp.run(f'unzip -o {teqc_zip_fn}',       shell=True)
        sp.run(f'rm -rf {teqc_zip_fn}',              shell=True)
        rv = sp.run(f'/tmp/teqc -help',              shell=True, capture_output=True )
        if rv.returncode == 0 :
            print('Installing teqc.')
            sp.run(f'mkdir -p {local_bin}',          shell=True)
            sp.run(f'mv -f teqc {local_bin}',        shell=True)  
            state = ' Teqc installed.'
            break
        else:
            print(f'Install failed.  rv.return={rv.returncode}')
            print(rv)
  else:
    a = 1;
    state='Teqc was already installed.'
  return state

# %% ../nbs/00_CORS.ipynb 33
def extract_year( date:str ):
  """
  Extract the year from a date string in the form: `"2023/1/1"`
  """
  Year = date.split('/')[0]
  return Year

# %% ../nbs/00_CORS.ipynb 38
def isTimeFormat(
  ts:str   # Time string as: HH:MM:SS
) ->bool:  # True if valid HH:MM:SS time string.
  """
  isTimeFormat(ts) checks the 'ts' input string for validity. A valid string is in
  this format: '13:34:56'.

  Returns True for a valid string,a nd False for invalid.
  """
  t = []
  rv = False;
  try:
      t = time.strptime(ts, '%H:%M:%S')
      rv = True;
  except ValueError:
      rv = False
  return rv

# %% ../nbs/00_CORS.ipynb 43
def utctoweekseconds(
  utc,                  # Date string 'YYYY/MM/DD'
  leapseconds           # For 2023, use -18
  ) ->tuple:            # (GPS_Week, GPS_day, Seconds_since_midnight)
  '''
    This function takes two parameters, utc and leapseconds, and returns the
    GPS week, the GPS day, and the seconds and microseconds since the beginning of the GPS week.

    Parameters:
    utc (datetime.datetime): The UTC time to be converted.
    leapseconds (int): The number of leap seconds to be added to the UTC time.
    See: 
    [GPS Leap Seconds](https://shorturl.at/jozO3)
    for more information.

    Returns:
    A tuple containing the GPS week, the GPS day, and the seconds and 
    microseconds since the beginning of the GPS week.

    The GPS week is an integer representing the number of weeks since the 
    beginning of the GPS epoch (1980-01-06 00:00:00).
    The GPS day is an integer representing the number of days since the 
    beginning of the GPS week.
    The seconds and microseconds since the beginning of the GPS week are both
    integers representing the number of seconds and microseconds since the
    beginning of the GPS week.

    Example:
    utc = datetime.datetime(2020, 1, 1, 0, 0, 0)
    leapseconds = 18

    utctoweekseconds(utc, leapseconds)

    Returns: (2086, 0, 0, 0)
  '''
  import datetime, calendar
  datetimeformat = "%Y-%m-%d %H:%M:%S"
  epoch = datetime.datetime.strptime("1980-01-06 00:00:00",datetimeformat)
  tdiff = utc -epoch  + datetime.timedelta(seconds=leapseconds)
  gpsweek = tdiff.days // 7 
  gpsdays = tdiff.days - 7*gpsweek         
  gpsseconds = tdiff.seconds + 86400* (tdiff.days -7*gpsweek) 
  return gpsweek,gpsdays,gpsseconds,tdiff.microseconds


# %% ../nbs/00_CORS.ipynb 45
def compute_day_of_year(
  date_str:str  # Date as 'YYYY/MM/DD'
) ->tuple:
  '''
    This function computes the day of the year from a given date
    string in the format 'YYYY/MM/DD'.

    Parameters:
    date_str (str): A string representing a date in the format 'YYYY/MM/DD'.

    Returns:
    A tuple containing the date in the following formats:
    ( YYYY/jjj,   YYYY-MMDD-Jjjj,   YYYY,   jjj,        DoW)', 
    where `YYYY` is the year, `jjj`: Juliean Day, `DoY` is the Day of the week. 
    
    Each tuple element has a particular purpose. The first element `YYYY/jjj` 
    represents the portion of the path used on the CORS web site.  The second
    element, `YYYY-MMDD-Jjjj` is used to generate the path to store downloaded
    data.  The `YYYY` is simply the year, and `jjj` is simple the Julean day of 
    the year, and `DoW` is the day of the week.  Each element is type str.


    Example:
    compute_day_of_year('2020/04/15')

    Returns:
    ('2020/105', '2020-0415-J105', '2020', '105', '04', '15')

    The returned tuple contains the day of the year in the format 'YYYY/DDD', 
    the year as a string, the day as a string, the month as a string, 
    and the day as a string. The first element of the tuple is the day 
    of the year in the format 'YYYY/DDD', which is the year followed by the 
    day of the year. The second element of the tuple is the year as a string. 
    The third element of the tuple is the day as a string. The fourth element
    of the tuple is the month as a string. The fifth element of the tuple is
    the day of the week as a string.
    
    The CORS path segment refers to the portion of the url that represents the
    date of the date.

  '''
  JDay = int(( datetime.datetime.strptime(date_str,'%Y/%m/%d') - datetime.datetime(int(date_str.split('/')[0]),1,1)).days + 1 )
  JDay = f'{JDay:03d}'
  date_parts =  date_str.split('/')
  Year = date_parts[0]
  Month = f'{int(date_parts[1]):02d}'
  Day   = f'{int(date_parts[2]):02d}'
  return f'{Year}/{JDay}', f'{Year}-{Month}{Day}-J{JDay}', Year, JDay, Month, Day

# %% ../nbs/00_CORS.ipynb 49
def getHTMLdocument(
  url      # The `url` to get. 
) -> str:  # the contents of the url as a string.
    response = requests.get(url)  # response will be provided in JSON format
    return response.text

# %% ../nbs/00_CORS.ipynb 52
def CORS_get_Support_url_list( 
  base_url:str,                        # COR url.
  date:str,                            # Date. Format: 'YYYY:MM:DD'
  file_types:str="sp3.gz|n.gz|g.gz"    # file types to get.
) -> list:                             # A list of CORS nav and SP3 files.
  """
  """
  data_url = base_url+compute_day_of_year( date )[0]
  hdoc = getHTMLdocument(data_url)
  soup = BeautifulSoup( hdoc, 'html.parser')
  urls = []
  for link in soup.find_all('a', attrs={'href' : re.compile(file_types, re.IGNORECASE) } ):
    #print(link.prettify())
    fn = link.get('href')
    url = f'{data_url}/{fn}'
    urls.append(url)
  return urls

# %% ../nbs/00_CORS.ipynb 55
def download_urls(
  url_list,            # List of urls to download.
  folder,              # Folder to store the downloads.
  clobber=False,       # True to overwrite, False to not overwrite existing files.
  id='',               # Optional `id` to use in the log file to identify the log.
  options='',          # `wget` options.
  cut_dirs=4           # Number of url subdirectories to trim.
) ->list:              # a list of return status strings for each download.
  '''
download_urls() is a function that downloads a list of URLs to a specified root directory.

Parameters:
url_list (list): A list of URLs to be downloaded.
root_dir (str): The root directory to which the URLs will be downloaded.
clobber (bool): A boolean value indicating whether existing files should be overwritten.
id (str): An optional identifier for the download.
options (str): An optional string of additional wget options.
    
    The function uses the wget command to download the URLs. The wget options used are:
    -nv: Not verbose
    -nc: No clobber (use for OSB files to avoid overwriting 1-Sec with 30-Sec)
    -np: No parent. (Important)
    -nH: Do not create a directory named after the url
    --cut-dirs=4: Remove the first four subdirs
    -R "index.html*": Do not keep the index.html* files.
    -P xxx: xxx will be the root directory

    Wget return codes:
      0   No problems occurred.
      1   Generic error code.
      2   Parse error---for instance, when parsing command-line options, the .wgetrc or .netrc...
      3   File I/O error.
      4   Network failure.
      5   SSL verification failure.
      6   Username/password authentication failure.
      7   Protocol errors.
      8   Server issued an error response.
  '''
  # Wget Options:
  # -nv                Not verbose
  # -nc                No clobber (use for OSB files to avoid 
  #                    overwriting 1-Sec with 30-Sec)
  # -np                No parent. ( Important !!! )
  # -nH                Do not create a directory named after the url
  # --cut-dirs=4       Remove the first four subdirs
  # -R "index.html*"   Do not keep the index.html* files.
  # -P xxx             xxx will be the root directory
  os.makedirs(folder, exist_ok=True)
  log_fn = datetime.datetime.now().strftime(f"{folder}/%Y-%m%d-%H%M%S-CORS-wget-{id}-log.txt")
  url_str = ' '.join(url_list)

  if clobber:
    nc_switch = ''
  else:
    nc_switch = '-nc '

  rv = sp.run( 
      'wget '\
      f'{nc_switch} '\
      f'-o {log_fn} '\
      '-nv '\
      f'-P {folder} '\
      '-np '\
      '-r '\
      '-nH '\
      '--connect-timeout=10 '\
      '--read-timeout=10 '\
      f'--cut-dirs={cut_dirs} '\
      '-R "index.html*,robots.txt,*.tmp" '\
      f'{url_str}',
        shell=True, capture_output=True)
  rv.stderr = log_fn
  rv.id = id
  return rv

# %% ../nbs/00_CORS.ipynb 58
def CORS_trim_to_time(
  f:str,      # RINEX file Name
  start:str,  # Start time str as `'YYYY-MM-DD HH:MM:SS.SSS'`
  stop:str):  # Stop time str  as `'YYYY-MM-DD HH:MM:SS.SSS'`
  
  """
Trims a RINEX file (f) to be between the 'start' and 'stop' times given.

This function takes in a file name (f), start time (start) and 
stop time (stop) as parameters and trims the file to the given time range.

The start and stop times are first converted to a format without colons, 
hyphens and periods. The teqc command is then used to trim the file to 
the given time range and the output is stored in a temporary file. 
The temporary file is then moved to the original file name.

Parameters:
f (str): The file name to be trimmed.
start (str): The start time in the format 'YYYY-MM-DD HH:MM:SS.SSS'.
stop (str): The stop time in the format 'YYYY-MM-DD HH:MM:SS.SSS'.

Returns:
rv (CompletedProcess): A CompletedProcess object containing information about the run command.
  """
  st = re.sub('[\:\-\.]', '', start)
  end = re.sub('[\:\-\.]', '', stop)
  print(f'CORS_trim_to_time(): f: {f}   start: {start}  stop: {stop}')
  rv = sp.run(f'teqc +out tmp.txt -st {start} -e {stop} {f}', shell=True)
  sp.run(f'mv tmp.txt {f}', shell=True)
  return rv

# %% ../nbs/00_CORS.ipynb 60
def CORS_get_station_log_url(
  station_list  # Python `list` of CORS Stations.
) ->list:       # A list of station log file urls
  '''
    This function takes a list of station names as an argument and 
    returns a list of URLs for the station log files.

    Parameters:
    station_list (list): A list of station names.

    Returns:
    lst (list): A list of URLs for the station log files.
  '''
  lst = []
  for station in station_list:
    station = str.lower(station)
    cords_file = f'{station_log_url}{station}.log.txt'
    lst.append(cords_file)
  return lst

# %% ../nbs/00_CORS.ipynb 63
def down_load_cors_station_log( 
  dir:str,            # Existing folder to place the file.
  station_list:list   # Python `list` of CORS Stations.
) ->list:             # a `dict` where `key` is the station ID, and `value` is path of the downloade file               
  '''
    This function downloads the log files of the given CORS stations 
    from the NGS website.

    Parameters:
    dir (str): The directory where the log files should be downloaded.
    station_list (list): A list of CORS station names.

    Returns:
    rv (dict): A dictionary containing the station name as the key and 
    the path of the downloaded log file as the value.
  '''
  log_file_list = CORS_get_station_log_url(station_list)
  rv = download_urls(log_file_list, dir, id='station', cut_dirs=1)
  return rv

# %% ../nbs/00_CORS.ipynb 66
def CORS_get_station_plots_url(
  station_list): # Python `list` of CORS Stations.
  '''
    This function takes a list of station names as an argument and 
    returns a list of URLs for the corresponding station plot 
    files.

    Parameters:
    station_list (list): A list of station names.

    Returns:
    lst (list): A list of URLs for the corresponding station plot
     files.
  '''
  # Example: https://geodesy.noaa.gov/corsdata/Plots/ab02_14.short.png
  lst = []
  for station in station_list:
    station = str.lower(station)
    short_plots_file = f'{plots_url}{station}_14.short.png'
    long_plots_file  = f'{plots_url}Longterm/{station}_14.long.png'
    lst.append(short_plots_file)
    lst.append(long_plots_file)
  return lst

# %% ../nbs/00_CORS.ipynb 69
def down_load_cors_plots( 
  dir:str,          # Existing folder to place the file.
  station_list:list # Python `list` of CORS Stations.
):
  '''
    This function downloads the plots of the CORS stations from
     the NGS website.

    Parameters:
        dir (str): The directory where the files will be downloaded.
        station_list (list): A list of CORS station names.

    Returns:
        rv (list): A list of the downloaded files.
  '''
  plots_file_list = CORS_get_station_plots_url(station_list)
  rv = download_urls(plots_file_list, dir, id='Plots', cut_dirs=1)
  return rv

# %% ../nbs/00_CORS.ipynb 72
def CORS_get_station_coords_url(
  station_list:list,  # Python `list` of CORS Stations.
) ->list:             # List of coordinates urls
  '''
    This function takes a list of station names as an argument and 
    returns a list of URLs for the corresponding station coordinates 
    files.

    Parameters:
    station_list (list): A list of station names.

    Returns:
    lst (list): A list of URLs for the corresponding station coordinates
     files.
  '''
  lst = []
  for station in station_list:
    station = str.lower(station)
    cords_file = f'{coords_url}{station}_14.coord.txt'
    lst.append(cords_file)
  return lst

# %% ../nbs/00_CORS.ipynb 76
def down_load_cors_station_coords( 
  dir:str,             # Existing folder to place the file.
  station_list:list ): # Python `list` of CORS Stations.
  '''
    This function downloads the coordinates of the CORS stations from the NGS website.

    Parameters:
        dir (str): The directory where the files will be downloaded.
        station_list (list): A list of CORS station names.

    Returns:
        rv (list): A list of the downloaded files.
  '''
  coords_file_list = CORS_get_station_coords_url(station_list)
  rv = download_urls(coords_file_list, dir, id='coords', cut_dirs=2)
  return rv

# %% ../nbs/00_CORS.ipynb 79
def clean_up_CORS(rdir:str,  # Directory start in.
                  date:str): # Date of files to clean up.
  """
  clean_up_CORS(rdir, date)
  Inputs:
  rdir      Directory to start the find command in.
  date      The date of the CORS files to cleanup.

  Outputs:
            Removes unnecessary files.
  Returns:
            None.

  Uses the Linux 'find' command to locate and remove unnecessary files 
  from within a CORS station directory.  
  """
  Year = date.split('/')[0][2:4]
  rv = sp.check_output(f'cd {rdir}; find -name *.md5 -delete; find -name *.{Year}d -delete; find -name *.md5* -delete; find -name *.{Year}S* -delete;', shell=True) 
  return rv


# %% ../nbs/00_CORS.ipynb 81
def down_load_list_of_obs_files( 
  folder='./',       # Existing folder to store downloaded CORS data.
  date='',           # Date to download. Format: 'YYYY:MM:DD'
  station_list=[] ): # List of CORS station identifiers.
  '''
    down_load_list_of_obs_files(folder, date, station_list)

    This function downloads a list of observation files from a given URL for a given date and station list.

    Parameters:
    folder (str): The folder where the files should be downloaded.
    date (str): The date for which the files should be downloaded.
    station_list (list): A list of stations for which the files should be downloaded.

    Returns:
    rv (list): A list of the downloaded files.
  '''
  # Create a string from the station list.
  station_url_list = []
  for station in station_list:
    data_url = '/'.join([ rinex_url+compute_day_of_year( date )[0], station.lower()+'/'] )
    station_url_list.append(data_url)
  
  # download the files.
  rv = download_urls(station_url_list, folder=folder,  id='OBS')
  return rv

# %% ../nbs/00_CORS.ipynb 83
def down_load_cors_data( 
  folder:str = '/tmp',      # Existing folder to store downloaded CORS data.
  date:str = '',            # Date to download. Format: 'YYYY:MM:DD'
  progress_callback = None, # User defined function to report progress
  station_list:list = []    # List of CORS station identifiers.
  ) ->list: 
  """
  Download CORS RINEX data for the designated `date`, specified identifiers in the
  `station_list`, and store
  the data in the given `folder`.
  """
  
  def show_progress(msg):
    print(msg)
    
  # Switch to the user defined progress function if one was supplied.
  if progress_callback:
    show_progress = progress_callback

  target_folder = f'{folder}/{compute_day_of_year(date)[1]}-CORS'
  show_progress(f'saving to: {target_folder}')
  rv_lst = []

  show_progress('Downloading info on selected stations.')
  rv = download_urls(cors_info_url_list, target_folder, id='info')
  rv_lst.append(rv)

  show_progress('Downloading selected OBS files.')
  rv = down_load_list_of_obs_files( 
    folder=target_folder, 
    date=date, 
    station_list=station_list
  )
  rv_lst.append(rv)

  show_progress('Downloading sp3 & nav files.')
  url_list = CORS_get_Support_url_list( rinex_url, date = date )
  sp3_nav_folder = '/'.join([target_folder, 'sp3_nav'])
  rv = download_urls(url_list, folder = sp3_nav_folder, id='sp3')
  rv_lst.append(rv)

  show_progress('Downloading station coords, logs, and plots.')
  for func in [down_load_cors_station_coords, 
               down_load_cors_station_log,
               down_load_cors_plots ]:
    rv = func(target_folder, station_list)
    rv_lst.append(rv)

  show_progress('All downloads completed.')
  return rv_lst
