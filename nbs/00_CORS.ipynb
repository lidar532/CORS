{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CORS\n",
    "\n",
    "> Python tool library to download collections of NOAA NGS RINEX datafiles from the CORS site."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp CORS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc  import *\n",
    "from fastcore.test  import *\n",
    "from fastcore.utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#| hide\n",
    "## imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#| hide\n",
    "### imports, public"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import datetime\n",
    "import time\n",
    "import os\n",
    "import glob\n",
    "import inspect\n",
    "import ipywidgets       as ipw\n",
    "import multiprocessing\n",
    "import numpy            as np\n",
    "import pandas           as pd\n",
    "import panel            as pn\n",
    "import re\n",
    "import requests\n",
    "import subprocess       as sp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#| hide\n",
    "### from public"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from   bs4              import BeautifulSoup\n",
    "from   pathlib          import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#| hide\n",
    "### imports, conditional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "try:\n",
    "  import google.colab\n",
    "  IN_COLAB = True\n",
    "except:\n",
    "  IN_COLAB = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Module Globals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`CORS_Lib_asof` is the date CORS library was compiled.\n",
    "\n",
    "`IN_COLAB` will be `True` if you are running in Google COlab\n",
    "and set to `False` otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "CORS_Lib_asof      = 'CORS_Lib_asof: 2023-0614-1908'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following module global variables hold the \n",
    "urls to the various parts of the NOAA CORS website."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "base_url           = 'https://geodesy.noaa.gov/'\n",
    "rinex_url          = base_url+'corsdata/rinex/'\n",
    "coords_url         = base_url+'corsdata/coord/coord_14/'\n",
    "plots_url          = base_url+'corsdata/Plots/'\n",
    "station_log_url    = base_url+'corsdata/station_log/'\n",
    "cors_info_url_list = [ base_url+'/corsdata/readme.txt', \n",
    "                      base_url+'/corsdata/RINEX211.txt' ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`test_folder` is the default folder where downloaded CORS data will be stored\n",
    "during testing of this package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "test_folder = '/tmp/test/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`wget_return_codes` are the code numbers and decoded descriptions returned by\n",
    "the [wget](https://www.gnu.org/software/wget/) program.  wget is used by this\n",
    "package to download the datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "wget_return_codes = ('0, No problems occurred.', \n",
    "                     '1, Generic error code.',\n",
    "                     '2, Parse error---for instance, when parsing command-line options, the .wgetrc or .netrc...',\n",
    "                     '3, File I/O error.',\n",
    "                     '4, Network failure.',\n",
    "                     '5, SSL verification failure.',\n",
    "                     '6, Username/password authentication failure.',\n",
    "                     '7, Protocol errors.',\n",
    "                     '8, Server issued an error response.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[`Teqc`](https://www.unavco.org/software/data-processing/teqc/teqc.html) \n",
    "is used to slice RINEX files by time.  The url list below are the full list\n",
    "of UNAVCO download sites for `teqc`.  The `install_teqc` function will download \n",
    "try each one and check that it works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "teqc_list          = [ \n",
    "    'https://www.unavco.org/software/data-processing/teqc/development/teqc_CentOSLx86_64s.zip',\n",
    "    'https://www.unavco.org/software/data-processing/teqc/development/teqc_CentOSLx86_64d.zip',\n",
    "    'https://www.unavco.org/software/data-processing/teqc/development/teqc_Lx86_64d.zip',\n",
    "    'https://www.unavco.org/software/data-processing/teqc/development/teqc_Lx86_64s.zip'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If running on Google Colab, the default path to store binary programs such\n",
    "as teqc is set below.  If not running in Colab, binarys will be stored in \n",
    "`~/bin` in the users home directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "if IN_COLAB:\n",
    "  local_bin = '/usr/local/bin'\n",
    "else:\n",
    "  local_bin = f'{str(Path.home())}/bin/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     IN_COLAB: False\n",
      "    local_bin: /home/wright/bin/\n",
      "CORS_Lib_asof: CORS_Lib_asof: 2023-0614-1908\n",
      "     base_url: https://geodesy.noaa.gov/\n",
      "    rinex_url: https://geodesy.noaa.gov/corsdata/rinex/\n"
     ]
    }
   ],
   "source": [
    "print(f'     IN_COLAB: {IN_COLAB}')\n",
    "print(f'    local_bin: {local_bin}')\n",
    "print(f'CORS_Lib_asof: {CORS_Lib_asof}')\n",
    "print(f'     base_url: {base_url}')\n",
    "print(f'    rinex_url: {rinex_url}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#| hide\n",
    "### def install_teqc():\n",
    "See: https://www.unavco.org/software/data-processing/teqc/teqc.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "# Get and install teqc\n",
    "def install_teqc() ->str:\n",
    "  '''\n",
    "  This function is used to download and install the teqc software from \n",
    "  Unavco. It first checks if the teqc software is already installed\n",
    "  in the system. If not, it downloads the teqc_Lx86_64s.zip file from\n",
    "  Unavco, unzips it, creates a local bin directory and moves the teqc\n",
    "  file to the local bin directory. Finally, it deletes the zip file.\n",
    "\n",
    "  See: https://www.unavco.org/software/data-processing/teqc/teqc.html\n",
    "  \n",
    "\n",
    "  Parameters:\n",
    "  None\n",
    "\n",
    "  Returns:\n",
    "  A string indicating the state of the installation. \n",
    "  It can be either: 'Teqc installed.', 'Teqc was already installed.', or\n",
    "  'teqc install failed.'\n",
    "  '''\n",
    "  state = 'initial.'\n",
    "  os.chdir('/tmp/')\n",
    "  print(f'install_teqc(): ')\n",
    "  rv = os.path.isfile(f'{local_bin}teqc')\n",
    "  if rv == False:\n",
    "    state = 'teqc install failed.'\n",
    "    for teqc_zip in teqc_list:\n",
    "        print(f'Downloading {teqc_zip} and installing Teqc from Unavco.  ')\n",
    "        sp.run(f'wget {teqc_zip}',                  shell=True)\n",
    "        teqc_zip_fn = teqc_zip.split( '/')[-1]\n",
    "        rv = sp.run(f'unzip -o {teqc_zip_fn}',       shell=True)\n",
    "        sp.run(f'rm -rf {teqc_zip_fn}',              shell=True)\n",
    "        rv = sp.run(f'/tmp/teqc -help',              shell=True, capture_output=True )\n",
    "        if rv.returncode == 0 :\n",
    "            print('Installing teqc.')\n",
    "            sp.run(f'mkdir -p {local_bin}',          shell=True)\n",
    "            sp.run(f'mv -f teqc {local_bin}',        shell=True)  \n",
    "            state = ' Teqc installed.'\n",
    "            break\n",
    "        else:\n",
    "            print(f'Install failed.  rv.return={rv.returncode}')\n",
    "            print(rv)\n",
    "  else:\n",
    "    a = 1;\n",
    "    state='Teqc was already installed.'\n",
    "  return state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "install_teqc(): \n",
      "Teqc was already installed.\n",
      "/home/wright/bin/teqc\n",
      "executable:  teqc\n",
      "version:     teqc  2019Feb25\n",
      "build:       Linux 2.6.32-573.12.1.x86_64|x86_64|gcc|Linux 64|=+\n"
     ]
    }
   ],
   "source": [
    "test_teqc_state = install_teqc()\n",
    "print(test_teqc_state)\n",
    "! which teqc\n",
    "! teqc -version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#| hide\n",
    "### def extract_year( date ):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def extract_year( date:str ):\n",
    "  \"\"\"\n",
    "  Extract the year from a date string in the form: `\"2023/1/1\"`\n",
    "  \"\"\"\n",
    "  Year = date.split('/')[0]\n",
    "  return Year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide \n",
    "test_eq(extract_year( '2023/1/20'), '2023')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2023'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_year( '2023/1/20')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#| hide\n",
    "### def isTimeFormat(ts):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def isTimeFormat(\n",
    "  ts:str   # Time string as: HH:MM:SS\n",
    ") ->bool:  # True if valid HH:MM:SS time string.\n",
    "  \"\"\"\n",
    "  isTimeFormat(ts) checks the 'ts' input string for validity. A valid string is in\n",
    "  this format: '13:34:56'.\n",
    "\n",
    "  Returns True for a valid string,a nd False for invalid.\n",
    "  \"\"\"\n",
    "  t = []\n",
    "  rv = False;\n",
    "  try:\n",
    "      t = time.strptime(ts, '%H:%M:%S')\n",
    "      rv = True;\n",
    "  except ValueError:\n",
    "      rv = False\n",
    "  return rv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we test the `isTimeFormat()` with several input times. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Returned\n",
      "Time      Value (rv)\n",
      "--------------------\n",
      "12:34:56  rv:True\n",
      "12:34     rv:False\n",
      "01:02:03  rv:True\n",
      "23:01:02  rv:True\n",
      "25:34:63  rv:False\n"
     ]
    }
   ],
   "source": [
    "print('          Returned\\n'\\\n",
    "      'Time      Value (rv)\\n'\\\n",
    "      '--------------------')\n",
    "for t in ['12:34:56',\n",
    "          '12:34',\n",
    "          '01:02:03',\n",
    "          '23:01:02',\n",
    "          '25:34:63']:\n",
    "  rv = isTimeFormat(t)\n",
    "  print(f'{t:9} rv:{rv}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12:34:56  rv:True True, \n",
      "12:34     rv:False False, Has no seconds.\n",
      "01:02:03  rv:True True, \n",
      "23:01:02  rv:True True, \n",
      "25:34:63  rv:False False, Seconds greater than 59\n"
     ]
    }
   ],
   "source": [
    "#| hide \n",
    "# Test isTimeFormat()\n",
    "test_eq( isTimeFormat('12:34:56'), True)\n",
    "test_eq( isTimeFormat('12:34'),   False)\n",
    "test_eq( isTimeFormat('01:02:03'), True)\n",
    "test_eq( isTimeFormat('01:02:03'), True)\n",
    "\n",
    "for t, trv, c in [\n",
    "              ('12:34:56', True,  \"\"),\n",
    "              ('12:34',   False,  \"Has no seconds.\"),\n",
    "              ('01:02:03', True,  \"\"),\n",
    "              ('23:01:02', True,  \"\"), \n",
    "              ('25:34:63', False, \"Seconds greater than 59\")\n",
    "             ]:\n",
    "  rv = isTimeFormat(t)\n",
    "  test_eq(rv, trv)\n",
    "  print(f'{t:9} rv:{rv} {trv}, {c}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#| hide\n",
    "### def utctoweekseconds(utc,leapseconds):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def utctoweekseconds(\n",
    "  utc,                  # Date string 'YYYY/MM/DD'\n",
    "  leapseconds           # For 2023, use -18\n",
    "  ) ->tuple:            # (GPS_Week, GPS_day, Seconds_since_midnight)\n",
    "  '''\n",
    "    This function takes two parameters, utc and leapseconds, and returns the\n",
    "    GPS week, the GPS day, and the seconds and microseconds since the beginning of the GPS week.\n",
    "\n",
    "    Parameters:\n",
    "    utc (datetime.datetime): The UTC time to be converted.\n",
    "    leapseconds (int): The number of leap seconds to be added to the UTC time.\n",
    "    See: \n",
    "    [GPS Leap Seconds](https://shorturl.at/jozO3)\n",
    "    for more information.\n",
    "\n",
    "    Returns:\n",
    "    A tuple containing the GPS week, the GPS day, and the seconds and \n",
    "    microseconds since the beginning of the GPS week.\n",
    "\n",
    "    The GPS week is an integer representing the number of weeks since the \n",
    "    beginning of the GPS epoch (1980-01-06 00:00:00).\n",
    "    The GPS day is an integer representing the number of days since the \n",
    "    beginning of the GPS week.\n",
    "    The seconds and microseconds since the beginning of the GPS week are both\n",
    "    integers representing the number of seconds and microseconds since the\n",
    "    beginning of the GPS week.\n",
    "\n",
    "    Example:\n",
    "    utc = datetime.datetime(2020, 1, 1, 0, 0, 0)\n",
    "    leapseconds = 18\n",
    "\n",
    "    utctoweekseconds(utc, leapseconds)\n",
    "\n",
    "    Returns: (2086, 0, 0, 0)\n",
    "  '''\n",
    "  import datetime, calendar\n",
    "  datetimeformat = \"%Y-%m-%d %H:%M:%S\"\n",
    "  epoch = datetime.datetime.strptime(\"1980-01-06 00:00:00\",datetimeformat)\n",
    "  tdiff = utc -epoch  + datetime.timedelta(seconds=leapseconds)\n",
    "  gpsweek = tdiff.days // 7 \n",
    "  gpsdays = tdiff.days - 7*gpsweek         \n",
    "  gpsseconds = tdiff.seconds + 86400* (tdiff.days -7*gpsweek) \n",
    "  return gpsweek,gpsdays,gpsseconds,tdiff.microseconds\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#| hide\n",
    "### def compute_day_of_year(date_str):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def compute_day_of_year(\n",
    "  date_str:str  # Date as 'YYYY/MM/DD'\n",
    ") ->tuple:\n",
    "  '''\n",
    "    This function computes the day of the year from a given date\n",
    "    string in the format 'YYYY/MM/DD'.\n",
    "\n",
    "    Parameters:\n",
    "    date_str (str): A string representing a date in the format 'YYYY/MM/DD'.\n",
    "\n",
    "    Returns:\n",
    "    A tuple containing the date in the following formats:\n",
    "    ( YYYY/jjj,   YYYY-MMDD-Jjjj,   YYYY,   jjj,        DoW)', \n",
    "    where `YYYY` is the year, `jjj`: Juliean Day, `DoY` is the Day of the week. \n",
    "    \n",
    "    Each tuple element has a particular purpose. The first element `YYYY/jjj` \n",
    "    represents the portion of the path used on the CORS web site.  The second\n",
    "    element, `YYYY-MMDD-Jjjj` is used to generate the path to store downloaded\n",
    "    data.  The `YYYY` is simply the year, and `jjj` is simple the Julean day of \n",
    "    the year, and `DoW` is the day of the week.  Each element is type str.\n",
    "\n",
    "\n",
    "    Example:\n",
    "    compute_day_of_year('2020/04/15')\n",
    "\n",
    "    Returns:\n",
    "    ('2020/105', '2020-0415-J105', '2020', '105', '04', '15')\n",
    "\n",
    "    The returned tuple contains the day of the year in the format 'YYYY/DDD', \n",
    "    the year as a string, the day as a string, the month as a string, \n",
    "    and the day as a string. The first element of the tuple is the day \n",
    "    of the year in the format 'YYYY/DDD', which is the year followed by the \n",
    "    day of the year. The second element of the tuple is the year as a string. \n",
    "    The third element of the tuple is the day as a string. The fourth element\n",
    "    of the tuple is the month as a string. The fifth element of the tuple is\n",
    "    the day of the week as a string.\n",
    "    \n",
    "    The CORS path segment refers to the portion of the url that represents the\n",
    "    date of the date.\n",
    "\n",
    "  '''\n",
    "  JDay = int(( datetime.datetime.strptime(date_str,'%Y/%m/%d') - datetime.datetime(int(date_str.split('/')[0]),1,1)).days + 1 )\n",
    "  JDay = f'{JDay:03d}'\n",
    "  date_parts =  date_str.split('/')\n",
    "  Year = date_parts[0]\n",
    "  Month = f'{int(date_parts[1]):02d}'\n",
    "  Day   = f'{int(date_parts[2]):02d}'\n",
    "  return f'{Year}/{JDay}', f'{Year}-{Month}{Day}-J{JDay}', Year, JDay, Month, Day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All returned data:\n",
      "Input Date     ( YYYY/jjj,   YYYY-MMDD-Jjjj,   YYYY,   jjj,        DoW)\n",
      "-----------------------------------------------------------------------\n",
      "2023/1/1     : ('2023/001', '2023-0101-J001', '2023', '001', '01', '01') \n",
      "2023/01/01   : ('2023/001', '2023-0101-J001', '2023', '001', '01', '01') \n",
      "2023/12/31   : ('2023/365', '2023-1231-J365', '2023', '365', '12', '31') \n",
      "2023/05/20   : ('2023/140', '2023-0520-J140', '2023', '140', '05', '20') \n",
      "\n",
      "Date           CORS path\n",
      "               segment only:\n",
      "2023/1/1     : 2023/001\n",
      "2023/01/01   : 2023/001\n",
      "2023/12/31   : 2023/365\n",
      "2023/05/20   : 2023/140\n"
     ]
    }
   ],
   "source": [
    "test_dates = [\n",
    "    '2023/1/1',\n",
    "    '2023/01/01',\n",
    "    '2023/12/31',\n",
    "    '2023/05/20'\n",
    "]\n",
    "print('All returned data:')\n",
    "print('Input Date     ( YYYY/jjj,   YYYY-MMDD-Jjjj,   YYYY,   jjj,        DoW)')\n",
    "print('-----------------------------------------------------------------------')\n",
    "for d in test_dates:\n",
    "  print( f'{d:12} : { compute_day_of_year(d) } ')\n",
    "\n",
    "print('\\nDate           CORS path\\n'\\\n",
    "       '               segment only:')\n",
    "for d in test_dates:\n",
    "  print( f'{d:12} : { compute_day_of_year(d)[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(1,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#| hide\n",
    "### def getHTMLdocument(url):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def getHTMLdocument(\n",
    "  url      # The `url` to get. \n",
    ") -> str:  # the contents of the url as a string.\n",
    "    response = requests.get(url)  # response will be provided in JSON format\n",
    "    return response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!DOCTYPE HTML PUBLIC \"-//W3C//DTD HTML 3.2 Final//EN\">\n",
      "<html>\n",
      " <head>\n",
      "  <title>Index of /corsdata/rinex</title>\n",
      " </head>\n",
      " <body>\n",
      "<h1>Index of /corsdata/rinex</h1>\n",
      "  <table>\n",
      "   <tr><th valign=\"top\"><img src=\"/icons/blank.gif\" alt=\"[ICO]\"></th><th><a href=\"?C=N;O=D\">Name</a></th><th><a href=\"?C=M;O=A\">Last modified</a></th><th><a href=\"?C=S;O=A\">Size</a></th><th><a href=\"?C=D;O=A\">Description</a></th></tr>\n",
      "   <tr><th colspan=\"5\"><hr></th></tr>\n"
     ]
    }
   ],
   "source": [
    "# Test  getHTMLdocument(rinex_url)\n",
    "test_html = getHTMLdocument(rinex_url)\n",
    "\n",
    "i = 0\n",
    "for line in test_html.splitlines():\n",
    "  print(line); i += 1\n",
    "  if i == 10:\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#| hide\n",
    "### def CORS_get_Support_url_list( base_url, date, file_types=\"sp3.gz|n.gz|g.gz\" ):\n",
    "See: https://www.geeksforgeeks.org/beautifulsoup-scraping-link-from-html/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def CORS_get_Support_url_list( \n",
    "  base_url:str,                        # COR url.\n",
    "  date:str,                            # Date. Format: 'YYYY:MM:DD'\n",
    "  file_types:str=\"sp3.gz|n.gz|g.gz\"    # file types to get.\n",
    ") -> list:                             # A list of CORS nav and SP3 files.\n",
    "  \"\"\"\n",
    "  \"\"\"\n",
    "  data_url = base_url+compute_day_of_year( date )[0]\n",
    "  hdoc = getHTMLdocument(data_url)\n",
    "  soup = BeautifulSoup( hdoc, 'html.parser')\n",
    "  urls = []\n",
    "  for link in soup.find_all('a', attrs={'href' : re.compile(file_types, re.IGNORECASE) } ):\n",
    "    #print(link.prettify())\n",
    "    fn = link.get('href')\n",
    "    url = f'{data_url}/{fn}'\n",
    "    urls.append(url)\n",
    "  return urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing: CORS_get_Support_url_list()\n",
      "sp3.gz and n.gz and g.gz\n",
      "https://geodesy.noaa.gov/corsdata/rinex/2023/143/IGS0OPSFIN_20231430000_01D_15M_ORB.SP3.gz\n",
      "https://geodesy.noaa.gov/corsdata/rinex/2023/143/IGS0OPSRAP_20231430000_01D_15M_ORB.SP3.gz\n",
      "https://geodesy.noaa.gov/corsdata/rinex/2023/143/IGS0OPSULT_20231430000_02D_15M_ORB.SP3.gz\n",
      "https://geodesy.noaa.gov/corsdata/rinex/2023/143/IGS0OPSULT_20231430600_02D_15M_ORB.SP3.gz\n",
      "https://geodesy.noaa.gov/corsdata/rinex/2023/143/IGS0OPSULT_20231431200_02D_15M_ORB.SP3.gz\n",
      "https://geodesy.noaa.gov/corsdata/rinex/2023/143/IGS0OPSULT_20231431800_02D_15M_ORB.SP3.gz\n",
      "https://geodesy.noaa.gov/corsdata/rinex/2023/143/brdc1430.23g.gz\n",
      "https://geodesy.noaa.gov/corsdata/rinex/2023/143/brdc1430.23n.gz\n",
      "https://geodesy.noaa.gov/corsdata/rinex/2023/143/igr22632.sp3.gz\n",
      "https://geodesy.noaa.gov/corsdata/rinex/2023/143/igs22632.sp3.gz\n",
      "https://geodesy.noaa.gov/corsdata/rinex/2023/143/igu22632_00.sp3.gz\n",
      "https://geodesy.noaa.gov/corsdata/rinex/2023/143/igu22632_06.sp3.gz\n",
      "https://geodesy.noaa.gov/corsdata/rinex/2023/143/igu22632_12.sp3.gz\n",
      "https://geodesy.noaa.gov/corsdata/rinex/2023/143/igu22632_18.sp3.gz\n",
      "\n",
      "sp3 only.\n",
      "https://geodesy.noaa.gov/corsdata/rinex/2023/143/IGS0OPSFIN_20231430000_01D_15M_ORB.SP3.gz\n",
      "https://geodesy.noaa.gov/corsdata/rinex/2023/143/IGS0OPSRAP_20231430000_01D_15M_ORB.SP3.gz\n",
      "https://geodesy.noaa.gov/corsdata/rinex/2023/143/IGS0OPSULT_20231430000_02D_15M_ORB.SP3.gz\n",
      "https://geodesy.noaa.gov/corsdata/rinex/2023/143/IGS0OPSULT_20231430600_02D_15M_ORB.SP3.gz\n",
      "https://geodesy.noaa.gov/corsdata/rinex/2023/143/IGS0OPSULT_20231431200_02D_15M_ORB.SP3.gz\n",
      "https://geodesy.noaa.gov/corsdata/rinex/2023/143/IGS0OPSULT_20231431800_02D_15M_ORB.SP3.gz\n",
      "https://geodesy.noaa.gov/corsdata/rinex/2023/143/igr22632.sp3.gz\n",
      "https://geodesy.noaa.gov/corsdata/rinex/2023/143/igs22632.sp3.gz\n",
      "https://geodesy.noaa.gov/corsdata/rinex/2023/143/igu22632_00.sp3.gz\n",
      "https://geodesy.noaa.gov/corsdata/rinex/2023/143/igu22632_06.sp3.gz\n",
      "https://geodesy.noaa.gov/corsdata/rinex/2023/143/igu22632_12.sp3.gz\n",
      "https://geodesy.noaa.gov/corsdata/rinex/2023/143/igu22632_18.sp3.gz\n",
      "\n",
      "n.gz and g.gz only.\n",
      "https://geodesy.noaa.gov/corsdata/rinex/2023/143/brdc1430.23g.gz\n",
      "https://geodesy.noaa.gov/corsdata/rinex/2023/143/brdc1430.23n.gz\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "print('Testing: CORS_get_Support_url_list()')\n",
    "print('sp3.gz and n.gz and g.gz')\n",
    "\n",
    "url = rinex_url\n",
    "sp3_and_nav_urls = CORS_get_Support_url_list(url, date='2023/05/23')\n",
    "for fn in sp3_and_nav_urls:\n",
    "  print(fn)\n",
    "\n",
    "print('\\nsp3 only.')\n",
    "file_types=\"sp3.gz\"\n",
    "sp3_urls = CORS_get_Support_url_list(url, date='2023/05/23', file_types=\"sp3.gz\")\n",
    "for fn in sp3_urls:\n",
    "  print(fn)\n",
    "\n",
    "print('\\nn.gz and g.gz only.')\n",
    "file_types=\"sp3.gz\"\n",
    "nav_urls = CORS_get_Support_url_list(url, date='2023/05/23', file_types=\"n.gz|g.gz\")\n",
    "for fn in nav_urls:\n",
    "  print(fn)\n",
    "print('Done.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#| hide\n",
    "### def download_urls(url_list, root_dir):\n",
    "Notes:\n",
    "1. It is important for a url to end in `/` \n",
    "when using recursive `-r` and `-np` options to `wget`. See: https://stackoverflow.com/questions/19004809/using-wget-to-recursively-fetch-a-directory-with-no-parent for details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def download_urls(\n",
    "  url_list,            # List of urls to download.\n",
    "  folder,              # Folder to store the downloads.\n",
    "  clobber=False,       # True to overwrite, False to not overwrite existing files.\n",
    "  id='',               # Optional `id` to use in the log file to identify the log.\n",
    "  options='',          # `wget` options.\n",
    "  cut_dirs=4           # Number of url subdirectories to trim.\n",
    ") ->list:              # a list of return status strings for each download.\n",
    "  '''\n",
    "download_urls() is a function that downloads a list of URLs to a specified root directory.\n",
    "\n",
    "Parameters:\n",
    "url_list (list): A list of URLs to be downloaded.\n",
    "root_dir (str): The root directory to which the URLs will be downloaded.\n",
    "clobber (bool): A boolean value indicating whether existing files should be overwritten.\n",
    "id (str): An optional identifier for the download.\n",
    "options (str): An optional string of additional wget options.\n",
    "    \n",
    "    The function uses the wget command to download the URLs. The wget options used are:\n",
    "    -nv: Not verbose\n",
    "    -nc: No clobber (use for OSB files to avoid overwriting 1-Sec with 30-Sec)\n",
    "    -np: No parent. (Important)\n",
    "    -nH: Do not create a directory named after the url\n",
    "    --cut-dirs=4: Remove the first four subdirs\n",
    "    -R \"index.html*\": Do not keep the index.html* files.\n",
    "    -P xxx: xxx will be the root directory\n",
    "\n",
    "    Wget return codes:\n",
    "      0   No problems occurred.\n",
    "      1   Generic error code.\n",
    "      2   Parse error---for instance, when parsing command-line options, the .wgetrc or .netrc...\n",
    "      3   File I/O error.\n",
    "      4   Network failure.\n",
    "      5   SSL verification failure.\n",
    "      6   Username/password authentication failure.\n",
    "      7   Protocol errors.\n",
    "      8   Server issued an error response.\n",
    "  '''\n",
    "  # Wget Options:\n",
    "  # -nv                Not verbose\n",
    "  # -nc                No clobber (use for OSB files to avoid \n",
    "  #                    overwriting 1-Sec with 30-Sec)\n",
    "  # -np                No parent. ( Important !!! )\n",
    "  # -nH                Do not create a directory named after the url\n",
    "  # --cut-dirs=4       Remove the first four subdirs\n",
    "  # -R \"index.html*\"   Do not keep the index.html* files.\n",
    "  # -P xxx             xxx will be the root directory\n",
    "  os.makedirs(folder, exist_ok=True)\n",
    "  log_fn = datetime.datetime.now().strftime(f\"{folder}/%Y-%m%d-%H%M%S-CORS-wget-{id}-log.txt\")\n",
    "  url_str = ' '.join(url_list)\n",
    "\n",
    "  if clobber:\n",
    "    nc_switch = ''\n",
    "  else:\n",
    "    nc_switch = '-nc '\n",
    "\n",
    "  rv = sp.run( \n",
    "      'wget '\\\n",
    "      f'{nc_switch} '\\\n",
    "      f'-o {log_fn} '\\\n",
    "      '-nv '\\\n",
    "      f'-P {folder} '\\\n",
    "      '-np '\\\n",
    "      '-r '\\\n",
    "      '-nH '\\\n",
    "      '--connect-timeout=10 '\\\n",
    "      '--read-timeout=10 '\\\n",
    "      f'--cut-dirs={cut_dirs} '\\\n",
    "      '-R \"index.html*,robots.txt,*.tmp\" '\\\n",
    "      f'{url_str}',\n",
    "        shell=True, capture_output=True)\n",
    "  rv.stderr = log_fn\n",
    "  rv.id = id\n",
    "  return rv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing: CORS_get_Support_url_list()\n",
      "Storing in folder: /tmp/test//sp3_nav\n",
      "             Date: 2023/04/28\n",
      "\n",
      "Urls downloaded\n",
      "https://geodesy.noaa.gov/corsdata/rinex/2023/118/IGS0OPSFIN_20231180000_01D_15M_ORB.SP3.gz\n",
      "https://geodesy.noaa.gov/corsdata/rinex/2023/118/IGS0OPSRAP_20231180000_01D_15M_ORB.SP3.gz\n",
      "https://geodesy.noaa.gov/corsdata/rinex/2023/118/IGS0OPSULT_20231180000_02D_15M_ORB.SP3.gz\n",
      "https://geodesy.noaa.gov/corsdata/rinex/2023/118/IGS0OPSULT_20231180600_02D_15M_ORB.SP3.gz\n",
      "https://geodesy.noaa.gov/corsdata/rinex/2023/118/IGS0OPSULT_20231181200_02D_15M_ORB.SP3.gz\n",
      "https://geodesy.noaa.gov/corsdata/rinex/2023/118/IGS0OPSULT_20231181800_02D_15M_ORB.SP3.gz\n",
      "https://geodesy.noaa.gov/corsdata/rinex/2023/118/brdc1180.23g.gz\n",
      "https://geodesy.noaa.gov/corsdata/rinex/2023/118/brdc1180.23n.gz\n",
      "https://geodesy.noaa.gov/corsdata/rinex/2023/118/igr22595.sp3.gz\n",
      "https://geodesy.noaa.gov/corsdata/rinex/2023/118/igs22595.sp3.gz\n",
      "https://geodesy.noaa.gov/corsdata/rinex/2023/118/igu22595_00.sp3.gz\n",
      "https://geodesy.noaa.gov/corsdata/rinex/2023/118/igu22595_06.sp3.gz\n",
      "https://geodesy.noaa.gov/corsdata/rinex/2023/118/igu22595_12.sp3.gz\n",
      "https://geodesy.noaa.gov/corsdata/rinex/2023/118/igu22595_18.sp3.gz\n",
      "\n",
      "Operation completed. The Wget response was: 0, No problems occurred.\n"
     ]
    }
   ],
   "source": [
    "# Test with some sp3 and nav data.\n",
    "test_url      = rinex_url\n",
    "fn = f'{test_folder}/sp3_nav'\n",
    "date = '2023/04/28'\n",
    "print('Testing: CORS_get_Support_url_list()')\n",
    "print(f'Storing in folder: {fn}\\n'\\\n",
    "      f'             Date: {date}\\n')\n",
    "\n",
    "test_url_list = CORS_get_Support_url_list(test_url, date = date)\n",
    "print('Urls downloaded')\n",
    "for url in test_url_list:\n",
    "  print(url)\n",
    "rv = download_urls(test_url_list, folder=fn, id='sp3')\n",
    "rv_str = wget_return_codes[rv.returncode]\n",
    "print(f'\\nOperation completed. The Wget response was: {rv_str}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#| hide\n",
    "### def CORS_trim_to_time(f, start, stop):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def CORS_trim_to_time(\n",
    "  f:str,      # RINEX file Name\n",
    "  start:str,  # Start time str as `'YYYY-MM-DD HH:MM:SS.SSS'`\n",
    "  stop:str):  # Stop time str  as `'YYYY-MM-DD HH:MM:SS.SSS'`\n",
    "  \n",
    "  \"\"\"\n",
    "Trims a RINEX file (f) to be between the 'start' and 'stop' times given.\n",
    "\n",
    "This function takes in a file name (f), start time (start) and \n",
    "stop time (stop) as parameters and trims the file to the given time range.\n",
    "\n",
    "The start and stop times are first converted to a format without colons, \n",
    "hyphens and periods. The teqc command is then used to trim the file to \n",
    "the given time range and the output is stored in a temporary file. \n",
    "The temporary file is then moved to the original file name.\n",
    "\n",
    "Parameters:\n",
    "f (str): The file name to be trimmed.\n",
    "start (str): The start time in the format 'YYYY-MM-DD HH:MM:SS.SSS'.\n",
    "stop (str): The stop time in the format 'YYYY-MM-DD HH:MM:SS.SSS'.\n",
    "\n",
    "Returns:\n",
    "rv (CompletedProcess): A CompletedProcess object containing information about the run command.\n",
    "  \"\"\"\n",
    "  st = re.sub('[\\:\\-\\.]', '', start)\n",
    "  end = re.sub('[\\:\\-\\.]', '', stop)\n",
    "  print(f'CORS_trim_to_time(): f: {f}   start: {start}  stop: {stop}')\n",
    "  rv = sp.run(f'teqc +out tmp.txt -st {start} -e {stop} {f}', shell=True)\n",
    "  sp.run(f'mv tmp.txt {f}', shell=True)\n",
    "  return rv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#| hide\n",
    "### def CORS_get_station_log_url(station_list):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def CORS_get_station_log_url(\n",
    "  station_list  # Python `list` of CORS Stations.\n",
    ") ->list:       # A list of station log file urls\n",
    "  '''\n",
    "    This function takes a list of station names as an argument and \n",
    "    returns a list of URLs for the station log files.\n",
    "\n",
    "    Parameters:\n",
    "    station_list (list): A list of station names.\n",
    "\n",
    "    Returns:\n",
    "    lst (list): A list of URLs for the station log files.\n",
    "  '''\n",
    "  lst = []\n",
    "  for station in station_list:\n",
    "    station = str.lower(station)\n",
    "    cords_file = f'{station_log_url}{station}.log.txt'\n",
    "    lst.append(cords_file)\n",
    "  return lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://geodesy.noaa.gov/corsdata/station_log/ncdu.log.txt',\n",
       " 'https://geodesy.noaa.gov/corsdata/station_log/ncbe.log.txt',\n",
       " 'https://geodesy.noaa.gov/corsdata/station_log/ncrt.log.txt',\n",
       " 'https://geodesy.noaa.gov/corsdata/station_log/loy2.log.txt']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n"
     ]
    }
   ],
   "source": [
    "station_list  = ['ncdu', 'ncbe', 'NCRT', 'loy2']\n",
    "local_test_folder = test_folder\n",
    "rv = CORS_get_station_log_url( station_list )\n",
    "display(rv)\n",
    "print('Done.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#| hide\n",
    "### def down_load_cors_station_log( dir, station_list):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def down_load_cors_station_log( \n",
    "  dir:str,            # Existing folder to place the file.\n",
    "  station_list:list   # Python `list` of CORS Stations.\n",
    ") ->list:             # a `dict` where `key` is the station ID, and `value` is path of the downloade file               \n",
    "  '''\n",
    "    This function downloads the log files of the given CORS stations \n",
    "    from the NGS website.\n",
    "\n",
    "    Parameters:\n",
    "    dir (str): The directory where the log files should be downloaded.\n",
    "    station_list (list): A list of CORS station names.\n",
    "\n",
    "    Returns:\n",
    "    rv (dict): A dictionary containing the station name as the key and \n",
    "    the path of the downloaded log file as the value.\n",
    "  '''\n",
    "  log_file_list = CORS_get_station_log_url(station_list)\n",
    "  rv = download_urls(log_file_list, dir, id='station', cut_dirs=1)\n",
    "  return rv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0, No problems occurred. See: /tmp/test//2023-0615-123209-CORS-wget-station-log.txt\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "station_list  = ['ncdu', 'ncbe', 'NCRT', 'loy2']\n",
    "local_test_folder = test_folder\n",
    "rv = down_load_cors_station_log( local_test_folder, station_list )\n",
    "print(f'{wget_return_codes[rv.returncode]} See: {rv.stderr}' )\n",
    "print('Done.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#| hide\n",
    "### def CORS_get_station_plots_url(station_list):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def CORS_get_station_plots_url(\n",
    "  station_list): # Python `list` of CORS Stations.\n",
    "  '''\n",
    "    This function takes a list of station names as an argument and \n",
    "    returns a list of URLs for the corresponding station plot \n",
    "    files.\n",
    "\n",
    "    Parameters:\n",
    "    station_list (list): A list of station names.\n",
    "\n",
    "    Returns:\n",
    "    lst (list): A list of URLs for the corresponding station plot\n",
    "     files.\n",
    "  '''\n",
    "  # Example: https://geodesy.noaa.gov/corsdata/Plots/ab02_14.short.png\n",
    "  lst = []\n",
    "  for station in station_list:\n",
    "    station = str.lower(station)\n",
    "    short_plots_file = f'{plots_url}{station}_14.short.png'\n",
    "    long_plots_file  = f'{plots_url}Longterm/{station}_14.long.png'\n",
    "    lst.append(short_plots_file)\n",
    "    lst.append(long_plots_file)\n",
    "  return lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing: CORS_get_station_plots_url()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['https://geodesy.noaa.gov/corsdata/Plots/ncdu_14.short.png',\n",
       " 'https://geodesy.noaa.gov/corsdata/Plots/Longterm/ncdu_14.long.png',\n",
       " 'https://geodesy.noaa.gov/corsdata/Plots/ncbe_14.short.png',\n",
       " 'https://geodesy.noaa.gov/corsdata/Plots/Longterm/ncbe_14.long.png',\n",
       " 'https://geodesy.noaa.gov/corsdata/Plots/ncrt_14.short.png',\n",
       " 'https://geodesy.noaa.gov/corsdata/Plots/Longterm/ncrt_14.long.png',\n",
       " 'https://geodesy.noaa.gov/corsdata/Plots/loy2_14.short.png',\n",
       " 'https://geodesy.noaa.gov/corsdata/Plots/Longterm/loy2_14.long.png']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n"
     ]
    }
   ],
   "source": [
    "print('Testing: CORS_get_station_plots_url()')\n",
    "station_list  = ['ncdu', 'ncbe', 'NCRT', 'loy2']\n",
    "rv = CORS_get_station_plots_url( station_list )\n",
    "display(rv)\n",
    "print('Done.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#| hide\n",
    "### def down_load_cors_plots( dir, station_list):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def down_load_cors_plots( \n",
    "  dir:str,          # Existing folder to place the file.\n",
    "  station_list:list # Python `list` of CORS Stations.\n",
    "):\n",
    "  '''\n",
    "    This function downloads the plots of the CORS stations from\n",
    "     the NGS website.\n",
    "\n",
    "    Parameters:\n",
    "        dir (str): The directory where the files will be downloaded.\n",
    "        station_list (list): A list of CORS station names.\n",
    "\n",
    "    Returns:\n",
    "        rv (list): A list of the downloaded files.\n",
    "  '''\n",
    "  plots_file_list = CORS_get_station_plots_url(station_list)\n",
    "  rv = download_urls(plots_file_list, dir, id='Plots', cut_dirs=1)\n",
    "  return rv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing: down_load_cors_plots_coords()\n",
      "8, Server issued an error response. See: /tmp/test//2023-0615-123209-CORS-wget-Plots-log.txt\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "print('Testing: down_load_cors_plots_coords()')\n",
    "station_list  = ['ncdu', 'ncbe', 'NCRT', 'loy2']\n",
    "local_test_folder = test_folder\n",
    "rv = down_load_cors_plots( local_test_folder, station_list )\n",
    "print(f'{wget_return_codes[rv.returncode]} See: {rv.stderr}' )\n",
    "print('Done.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#| hide\n",
    "### def CORS_get_station_coords_url(dir, station_list):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def CORS_get_station_coords_url(\n",
    "  station_list:list,  # Python `list` of CORS Stations.\n",
    ") ->list:             # List of coordinates urls\n",
    "  '''\n",
    "    This function takes a list of station names as an argument and \n",
    "    returns a list of URLs for the corresponding station coordinates \n",
    "    files.\n",
    "\n",
    "    Parameters:\n",
    "    station_list (list): A list of station names.\n",
    "\n",
    "    Returns:\n",
    "    lst (list): A list of URLs for the corresponding station coordinates\n",
    "     files.\n",
    "  '''\n",
    "  lst = []\n",
    "  for station in station_list:\n",
    "    station = str.lower(station)\n",
    "    cords_file = f'{coords_url}{station}_14.coord.txt'\n",
    "    lst.append(cords_file)\n",
    "  return lst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example usage:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing: CORS_get_station_coords_url()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['https://geodesy.noaa.gov/corsdata/coord/coord_14/ncdu_14.coord.txt',\n",
       " 'https://geodesy.noaa.gov/corsdata/coord/coord_14/ncbe_14.coord.txt',\n",
       " 'https://geodesy.noaa.gov/corsdata/coord/coord_14/ncrt_14.coord.txt',\n",
       " 'https://geodesy.noaa.gov/corsdata/coord/coord_14/loy2_14.coord.txt']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n"
     ]
    }
   ],
   "source": [
    "print('Testing: CORS_get_station_coords_url()')\n",
    "station_list  = ['ncdu', 'ncbe', 'NCRT', 'loy2']\n",
    "rv = CORS_get_station_coords_url( station_list )\n",
    "display(rv)\n",
    "print('Done.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#| hide\n",
    "### def down_load_cors_station_coords( dir, station_list):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def down_load_cors_station_coords( \n",
    "  dir:str,             # Existing folder to place the file.\n",
    "  station_list:list ): # Python `list` of CORS Stations.\n",
    "  '''\n",
    "    This function downloads the coordinates of the CORS stations from the NGS website.\n",
    "\n",
    "    Parameters:\n",
    "        dir (str): The directory where the files will be downloaded.\n",
    "        station_list (list): A list of CORS station names.\n",
    "\n",
    "    Returns:\n",
    "        rv (list): A list of the downloaded files.\n",
    "  '''\n",
    "  coords_file_list = CORS_get_station_coords_url(station_list)\n",
    "  rv = download_urls(coords_file_list, dir, id='coords', cut_dirs=2)\n",
    "  return rv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing: down_load_cors_station_coords()\n",
      "0, No problems occurred. See: /tmp/test//2023-0615-123209-CORS-wget-coords-log.txt\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "print('Testing: down_load_cors_station_coords()')\n",
    "station_list  = ['ncdu', 'ncbe', 'NCRT', 'loy2']\n",
    "local_test_folder = test_folder\n",
    "rv = down_load_cors_station_coords( local_test_folder, station_list )\n",
    "print(f'{wget_return_codes[rv.returncode]} See: {rv.stderr}' )\n",
    "print('Done.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#| hide\n",
    "### def clean_up_CORS(rdir, date):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def clean_up_CORS(rdir:str,  # Directory start in.\n",
    "                  date:str): # Date of files to clean up.\n",
    "  \"\"\"\n",
    "  clean_up_CORS(rdir, date)\n",
    "  Inputs:\n",
    "  rdir      Directory to start the find command in.\n",
    "  date      The date of the CORS files to cleanup.\n",
    "\n",
    "  Outputs:\n",
    "            Removes unnecessary files.\n",
    "  Returns:\n",
    "            None.\n",
    "\n",
    "  Uses the Linux 'find' command to locate and remove unnecessary files \n",
    "  from within a CORS station directory.  \n",
    "  \"\"\"\n",
    "  Year = date.split('/')[0][2:4]\n",
    "  rv = sp.check_output(f'cd {rdir}; find -name *.md5 -delete; find -name *.{Year}d -delete; find -name *.md5* -delete; find -name *.{Year}S* -delete;', shell=True) \n",
    "  return rv\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#| hide\n",
    "### def down_load_list_of_obs_files( folder='./', date='' station_list=[] ): "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def down_load_list_of_obs_files( \n",
    "  folder='./',       # Existing folder to store downloaded CORS data.\n",
    "  date='',           # Date to download. Format: 'YYYY:MM:DD'\n",
    "  station_list=[] ): # List of CORS station identifiers.\n",
    "  '''\n",
    "    down_load_list_of_obs_files(folder, date, station_list)\n",
    "\n",
    "    This function downloads a list of observation files from a given URL for a given date and station list.\n",
    "\n",
    "    Parameters:\n",
    "    folder (str): The folder where the files should be downloaded.\n",
    "    date (str): The date for which the files should be downloaded.\n",
    "    station_list (list): A list of stations for which the files should be downloaded.\n",
    "\n",
    "    Returns:\n",
    "    rv (list): A list of the downloaded files.\n",
    "  '''\n",
    "  # Create a string from the station list.\n",
    "  station_url_list = []\n",
    "  for station in station_list:\n",
    "    data_url = '/'.join([ rinex_url+compute_day_of_year( date )[0], station.lower()+'/'] )\n",
    "    station_url_list.append(data_url)\n",
    "  \n",
    "  # download the files.\n",
    "  rv = download_urls(station_url_list, folder=folder,  id='OBS')\n",
    "  return rv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#| hide\n",
    "### def down_load_cors_data( folder = '/', date   = '', station_list = [] ):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def down_load_cors_data( \n",
    "  folder:str = '/tmp',      # Existing folder to store downloaded CORS data.\n",
    "  date:str = '',            # Date to download. Format: 'YYYY:MM:DD'\n",
    "  progress_callback = None, # User defined function to report progress\n",
    "  station_list:list = []    # List of CORS station identifiers.\n",
    "  ) ->list: \n",
    "  \"\"\"\n",
    "  Download CORS RINEX data for the designated `date`, specified identifiers in the\n",
    "  `station_list`, and store\n",
    "  the data in the given `folder`.\n",
    "  \"\"\"\n",
    "  \n",
    "  def show_progress(msg):\n",
    "    print(msg)\n",
    "    \n",
    "  # Switch to the user defined progress function if one was supplied.\n",
    "  if progress_callback:\n",
    "    show_progress = progress_callback\n",
    "\n",
    "  target_folder = f'{folder}/{compute_day_of_year(date)[1]}-CORS'\n",
    "  show_progress(f'saving to: {target_folder}')\n",
    "  rv_lst = []\n",
    "\n",
    "  show_progress('Downloading info on selected stations.')\n",
    "  rv = download_urls(cors_info_url_list, target_folder, id='info')\n",
    "  rv_lst.append(rv)\n",
    "\n",
    "  show_progress('Downloading selected OBS files.')\n",
    "  rv = down_load_list_of_obs_files( \n",
    "    folder=target_folder, \n",
    "    date=date, \n",
    "    station_list=station_list\n",
    "  )\n",
    "  rv_lst.append(rv)\n",
    "\n",
    "  show_progress('Downloading sp3 & nav files.')\n",
    "  url_list = CORS_get_Support_url_list( rinex_url, date = date )\n",
    "  sp3_nav_folder = '/'.join([target_folder, 'sp3_nav'])\n",
    "  rv = download_urls(url_list, folder = sp3_nav_folder, id='sp3')\n",
    "  rv_lst.append(rv)\n",
    "\n",
    "  show_progress('Downloading station coords, logs, and plots.')\n",
    "  for func in [down_load_cors_station_coords, \n",
    "               down_load_cors_station_log,\n",
    "               down_load_cors_plots ]:\n",
    "    rv = func(target_folder, station_list)\n",
    "    rv_lst.append(rv)\n",
    "\n",
    "  show_progress('All downloads completed.')\n",
    "  return rv_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
